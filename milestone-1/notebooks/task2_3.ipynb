{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 3: Milestone I | Natural Language Processing**\n",
    "## **Task 2 & 3. Generating Feature Representations & Classifying Clothing Reviews**\n",
    "\n",
    "**Group 01:**\n",
    "- Tran Tu Tam (s3999159)\n",
    "- Phan Nhat Minh (s3978598)\n",
    "- Le Thien Son (s3977955)\n",
    "\n",
    "**Environment**: \n",
    "\n",
    "To ensure full reproducibility, the Python environment used in this assignment is managed with **conda**. We worked with **Python 3.10** on **conda 25.7.0** inside Jupyter Notebook.  \n",
    "\n",
    "The exact environment can be recreated by running the following command with the provided `environment.yaml` file:\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yaml\n",
    "```\n",
    "\n",
    "After creating the environment, activate it with:\n",
    "\n",
    "```bash\n",
    "conda activate ap4ds-a3\n",
    "```\n",
    "\n",
    "**Libraries used**: \n",
    "* re, collections.Counter\n",
    "* numpy, pandas, scipy\n",
    "* matplotlib, seaborn\n",
    "* gensim (KeyedVectors, downloader API)\n",
    "* scikit-learn (model_selection, pipeline, preprocessing, feature_extraction, metrics, classifiers)\n",
    "* imbalanced-learn (SMOTE, Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we continue from the preprocessing work in **Task 1** and focus on two main goals:  \n",
    "\n",
    "- **Task 2: Generating Feature Representations**  \n",
    "  We transform the cleaned clothing reviews into numerical formats suitable for machine learning.  \n",
    "  Three types of representations are built:  \n",
    "  - **Bag-of-Words (BoW)** using the fixed vocabulary from Task 1  \n",
    "  - **Unweighted embeddings** (FastText average vectors)  \n",
    "  - **TF-IDF weighted embeddings** (FastText weighted by IDF scores)  \n",
    "  Along the way, we check coverage of the embedding model, inspect out-of-vocabulary cases, and save the representations for downstream tasks.  \n",
    "\n",
    "- **Task 3: Clothing Review Classification**  \n",
    "  Using the generated features, we train and evaluate multiple classifiers to predict whether a clothing item is **recommended** or not (`Recommended IND`).  \n",
    "  - **Question 1:** Which representation (BoW vs embeddings) works best?  \n",
    "  - **Question 2:** Does adding the **Title** of reviews improve performance compared to Text alone?  \n",
    "\n",
    "For both questions, we use **cross-validation** with multiple metrics (Accuracy, F1, ROC-AUC, Balanced Accuracy) to account for class imbalance.  \n",
    "We also experiment with **SMOTE oversampling** vs **class weighting** to handle imbalance in the target labels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Third-Party Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP & Embeddings\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Machine Learning (Scikit-learn)\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Imbalanced Data Handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignore only ConvergenceWarning from sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "# (optional) also suppress generic UserWarning if needed\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Clothing Reviews\n",
    "\n",
    "With preprocessing done in Task 1, the next step is to turn the cleaned reviews into numerical features.  \n",
    "These representations let us feed the text into machine learning models later in Task 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Processed Data\n",
    "\n",
    "To begin, we load the cleaned dataset from Task 1 (`processed.csv`).  \n",
    "This file includes the tokenized and filtered reviews, and for this step we focus on the `Review Text` column.  \n",
    "\n",
    "We then convert these reviews into a list of strings so they can be used directly when creating the different feature representations in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of processed reviews:\n",
      "[\"['high', 'hope', 'wanted', 'work', 'initially', 'petite', 'usual', 'found', 'outrageously', 'fact', 'zip', 'reordered', 'petite', 'medium', 'half', 'nicely', 'bottom', 'half', 'tight', 'layer', 'cheap', 'net', 'layer', 'imo', 'major', 'design', 'flaw', 'net', 'layer', 'sewn', 'directly', 'zipper']\", \"['jumpsuit', 'fun', 'flirty', 'fabulous', 'time', 'compliment']\", \"['shirt', 'due', 'adjustable', 'front', 'tie', 'length', 'legging', 'sleeveless', 'pair', 'cardigan', 'shirt']\", \"['tracy', 'reese', 'dress', 'petite', 'foot', 'tall', 'brand', 'pretty', 'package', 'lot', 'skirt', 'long', 'full', 'overwhelmed', 'frame', 'stranger', 'alteration', 'shortening', 'skirt', 'embellishment', 'garment', 'idea', 'style', 'work', 'returned']\", \"['basket', 'hte', 'person', 'store', 'pick', 'teh', 'pale', 'hte', 'gorgeous', 'turn', 'perfectly', 'baggy', 'hte', 'x', 'hte', 'bummer', 'petite', 'decided', 'jeans', 'pant', 'skirt', 'oops']\"]\n"
     ]
    }
   ],
   "source": [
    "# Load the processed dataset from Task 1\n",
    "df = pd.read_csv(\"../output/processed.csv\")\n",
    "\n",
    "# Keep only non-empty processed token lists\n",
    "df = df[df[\"processed_tokens\"].str.strip().astype(bool)]\n",
    "\n",
    "# Convert the cleaned tokens back into review strings (space-joined)\n",
    "reviews = df[\"processed_tokens\"].astype(str).tolist()\n",
    "\n",
    "print(\"Head of processed reviews:\")\n",
    "print(reviews[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19652, 13)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the vocabulary file created in Task 1.  \n",
    "\n",
    "The file `vocab.txt` contains all valid tokens from the processed reviews, each mapped to a unique integer index. This mapping is important because it keeps our feature representations in Task 2 aligned to a **consistent and reproducible index space**.  \n",
    "\n",
    "We read the file line by line, split each entry into the token and its index, and store them in a Python dictionary called `vocab`. This dictionary will be our reference point for building bag-of-words vectors and other feature encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of vocab:\n",
      "a-cup: 0\n",
      "a-flutter: 1\n",
      "a-frame: 2\n",
      "a-kind: 3\n",
      "a-line: 4\n"
     ]
    }
   ],
   "source": [
    "with open(\"../output/vocab.txt\", \"r\") as f:\n",
    "    vocab_lines = f.readlines()\n",
    "\n",
    "vocab = {line.split(\":\")[0]: int(line.strip().split(\":\")[1]) for line in vocab_lines}\n",
    "\n",
    "print(\"\\nHead of vocab:\")\n",
    "for i, (word, idx) in enumerate(vocab.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"{word}: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bag-of-Words Model: Count Vector Representation\n",
    "\n",
    "We start by generating the **bag-of-words (BoW) representation** for each review. This approach converts each review into a sparse vector where:  \n",
    "- The **index** corresponds to a token from the vocabulary created in Task 1.  \n",
    "- The **value** shows how many times that token appears in the review.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CountVectorizer using fixed vocab\n",
    "vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "X_counts = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load FastText Word Vectors\n",
    "\n",
    "For the embedding model, we use **FastText** from `gensim`’s API (`fasttext-wiki-news-subwords-300`).  \n",
    "This pre-trained model maps each word into a 300-dimensional vector and can handle **out-of-vocabulary (OOV)** words by using subword information. That makes it especially useful for messy, user-generated reviews where typos and rare words are common.  \n",
    "\n",
    "Once loaded, we confirm the embedding dimension and use these vectors to build:  \n",
    "- **Unweighted document vectors** (average of word embeddings).  \n",
    "- **Weighted document vectors** (TF-IDF weighted average).  \n",
    "\n",
    "These representations will feed into our classification models in Task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText model from gensim... (This may take a few minutes on the first run)\n",
      "Embedding dimension: 300\n"
     ]
    }
   ],
   "source": [
    "# Download FastText model from gensim\n",
    "print(\"Loading FastText model from gensim... (This may take a few minutes on the first run)\")\n",
    "ft_model = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "embedding_dim = ft_model.vector_size\n",
    "\n",
    "# Check if the model is loaded correctly\n",
    "print(\"Embedding dimension:\", embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Tokenization Consistency\n",
    "\n",
    "To make sure our feature extraction is accurate, we re-tokenize the reviews into word lists before applying Bag-of-Words or embedding methods.  \n",
    "We use the **same regex pattern** from Task 1 so that the tokens stay consistent with the vocabulary and preprocessing already applied.  \n",
    "This step ensures that every feature representation aligns with the cleaned dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = re.compile(r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\") \n",
    "\n",
    "def tokenize(text): \n",
    "    tokens = tokenizer.findall(text.lower()) \n",
    "    clean_tokens = [t.strip(\"-'\") for t in tokens] # remove trailing punctuation if needed \n",
    "    return clean_tokens \n",
    "\n",
    "tokenized_reviews = [tokenize(r) for r in reviews] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 OOV Diagnostics\n",
    "\n",
    "We checked how well the FastText model covers our dataset vocabulary by calculating the out-of-vocabulary (OOV) rate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText OOV Coverage: {'total_tokens': 355512, 'covered_tokens': 353286, 'coverage_pct': 99.37}\n"
     ]
    }
   ],
   "source": [
    "def compute_coverage(token_lists, model):\n",
    "    total = sum(len(toks) for toks in token_lists)\n",
    "    known = sum(sum(1 for tok in toks if tok in model) for toks in token_lists)\n",
    "    return {\n",
    "        \"total_tokens\": total,\n",
    "        \"covered_tokens\": known,\n",
    "        \"coverage_pct\": round(100 * known / total, 2)\n",
    "    }\n",
    "\n",
    "coverage = compute_coverage(tokenized_reviews, ft_model)\n",
    "print(\"FastText OOV Coverage:\", coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model covers **99.37%** of all tokens, leaving only **0.63%** unmatched.  \n",
    "This high coverage suggests FastText handles our reviews very well. Still, we take a closer look at the OOV cases to confirm they won’t affect downstream results in a meaningful way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top OOV tokens: [('pilcro', 274), ('maeve', 156), ('xsp', 92), (\"would've\", 83), ('xxsp', 77), (\"retailer's\", 56), ('xsmall', 48), (\"could've\", 38), (\"model's\", 35), ('cartonnier', 23)]\n",
      "All missing tokens:\n",
      "linen-like: 5\n",
      "year's: 15\n",
      "xsp: 92\n",
      "would've: 83\n",
      "bralette: 21\n",
      "could've: 38\n",
      "antro: 12\n",
      "should've: 19\n",
      "square-apple: 2\n",
      "jammie: 2\n",
      "sweater-like: 6\n",
      "cami's: 3\n",
      "swtr: 5\n",
      "maeve: 156\n",
      "that'll: 2\n",
      "xxsp: 77\n",
      "ranna: 3\n",
      "pants-they: 2\n",
      "pilcro: 274\n",
      "xsmall: 48\n",
      "woman's: 9\n",
      "small-chested: 10\n",
      "xs-s: 13\n",
      "retailer's: 56\n",
      "antho: 12\n",
      "v-cut: 4\n",
      "work-appropriate: 7\n",
      "maternity-ish: 8\n",
      "maternity-esque: 2\n",
      "friend's: 8\n",
      "season's: 4\n",
      "as-pictured: 3\n",
      "xspetite: 16\n",
      "peek-a: 7\n",
      "marled: 12\n",
      "flatering: 8\n",
      "today's: 3\n",
      "flirtiness: 2\n",
      "fit-and: 7\n",
      "c-cup: 2\n",
      "valentine's: 5\n",
      "cartonnier: 23\n",
      "one's: 20\n",
      "racerback: 9\n",
      "true-to: 21\n",
      "m-l: 5\n",
      "mid-shin: 2\n",
      "model's: 35\n",
      "throw-on: 6\n",
      "and-go: 3\n",
      "husband's: 11\n",
      "mockneck: 4\n",
      "lbd: 13\n",
      "flowiness: 6\n",
      "amalfi: 3\n",
      "skinny's: 3\n",
      "under-layer: 6\n",
      "orange-y: 2\n",
      "purchas: 5\n",
      "moulinette: 9\n",
      "sweatercoat: 7\n",
      "she's: 23\n",
      "d-dd: 7\n",
      "comf: 5\n",
      "pointelle: 9\n",
      "mid-hip: 3\n",
      "fit's: 5\n",
      "dind't: 16\n",
      "tencel: 9\n",
      "d's: 4\n",
      "camis: 7\n",
      "flowey: 11\n",
      "colletage: 2\n",
      "xs's: 2\n",
      "brother's: 5\n",
      "lot's: 2\n",
      "canvas-y: 2\n",
      "skir: 2\n",
      "super-flattering: 4\n",
      "whiskering: 7\n",
      "evanthe: 3\n",
      "xxxl: 3\n",
      "sister-in: 2\n",
      "poofing: 5\n",
      "gauze-like: 4\n",
      "akemi: 6\n",
      "charlie's: 4\n",
      "grandma's: 4\n",
      "errand-running: 2\n",
      "sleev: 5\n",
      "above-the: 3\n",
      "feminie: 2\n",
      "pear-shape: 13\n",
      "deletta: 19\n",
      "x-s: 3\n",
      "large-chested: 6\n",
      "rouching: 6\n",
      "maxi's: 3\n",
      "moo-moo: 2\n",
      "pxxs: 14\n",
      "dress's: 6\n",
      "seafolly: 7\n",
      "body-skimming: 4\n",
      "retu: 2\n",
      "maeve's: 5\n",
      "druzy: 2\n",
      "becau: 3\n",
      "demin: 6\n",
      "fairisle: 2\n",
      "heathered: 20\n",
      "stevies: 12\n",
      "arielle: 2\n",
      "flowly: 6\n",
      "men's: 6\n",
      "non-petite: 6\n",
      "colros: 7\n",
      "mid-knee: 4\n",
      "reviewer's: 10\n",
      "underslip: 4\n",
      "mother's: 13\n",
      "day's: 2\n",
      "clorox: 2\n",
      "levi's: 4\n",
      "fabric's: 4\n",
      "didn't: 2\n",
      "semi-fitted: 2\n",
      "arty-looking: 2\n",
      "mom's: 4\n",
      "child's: 6\n",
      "collector's: 2\n",
      "woolite: 3\n",
      "slee: 2\n",
      "wasn't: 4\n",
      "mom-bod: 2\n",
      "pilcros: 12\n",
      "s-m: 4\n",
      "llbean: 2\n",
      "wasit: 6\n",
      "static-y: 2\n",
      "neira: 4\n",
      "daughter's: 10\n",
      "linin: 2\n",
      "scratchier: 3\n",
      "pajama-like: 2\n",
      "tegan: 7\n",
      "hi-low: 7\n",
      "cupro: 3\n",
      "tailor-fitted: 2\n",
      "regular-length: 2\n",
      "produ: 2\n",
      "xl's: 3\n",
      "dryel: 3\n",
      "a-symmetric: 2\n",
      "blousey: 14\n",
      "natori: 5\n",
      "marrakech: 4\n",
      "t-neck: 5\n",
      "anyone's: 6\n",
      "otk: 2\n",
      "side-zipper: 2\n",
      "muffin-top: 2\n",
      "ombr: 5\n",
      "colorblocked: 2\n",
      "super-tiny: 2\n",
      "antrho: 8\n",
      "buttondown: 8\n",
      "isn't: 2\n",
      "shirt's: 3\n",
      "non-bulky: 2\n",
      "flowier: 2\n",
      "petitie: 7\n",
      "everyone's: 4\n",
      "verdugo: 4\n",
      "children's: 2\n",
      "derri: 5\n",
      "v-neckline: 2\n",
      "hemstitch: 2\n",
      "rec'd: 2\n",
      "souers: 2\n",
      "easy-breezy: 2\n",
      "falttering: 8\n",
      "law's: 2\n",
      "corodorys: 2\n",
      "uncuff: 3\n",
      "stretchier: 3\n",
      "niece's: 2\n",
      "sister's: 6\n",
      "light-to: 2\n",
      "pilco: 10\n",
      "jacket's: 2\n",
      "y'all: 2\n",
      "double-v: 2\n",
      "l-xl: 2\n",
      "tie-neck: 4\n",
      "relaxed-fit: 2\n",
      "sacklike: 4\n",
      "v's: 2\n",
      "mock-neck: 2\n",
      "cowlneck: 4\n",
      "fit-wise: 2\n",
      "knit-like: 2\n",
      "winter's: 2\n",
      "flow-y: 7\n",
      "spetite: 2\n",
      "looooooove: 2\n",
      "retailergologie: 4\n",
      "shearling-lined: 2\n",
      "women's: 8\n",
      "size-small: 2\n",
      "ann's: 2\n",
      "a-frame: 2\n",
      "eloise: 2\n",
      "tenty: 2\n",
      "endora: 2\n",
      "fetherston: 2\n",
      "pop-back: 4\n",
      "versat: 2\n",
      "sale-on: 2\n",
      "slubby: 2\n",
      "nordstrom: 2\n",
      "shooties: 2\n",
      "show-through: 3\n",
      "jewel-tone: 2\n",
      "mid-september: 2\n",
      "colorblock: 3\n",
      "clingier: 2\n",
      "long-waisted: 9\n",
      "slenderizing: 5\n",
      "top's: 4\n",
      "medium-to: 2\n",
      "juuuust: 2\n",
      "manufacturer's: 4\n",
      "grecian: 3\n",
      "c-d: 2\n",
      "pepto: 3\n",
      "supima: 5\n",
      "ag's: 2\n",
      "color-wise: 3\n",
      "pintucks: 2\n",
      "pilly: 2\n",
      "swea: 3\n",
      "bodytype: 2\n",
      "kedia: 2\n",
      "small-busted: 5\n",
      "girl's: 2\n",
      "a-cup: 2\n",
      "over-shirt: 3\n",
      "paquerette: 3\n",
      "pj's: 5\n",
      "coh's: 2\n",
      "jean's: 3\n",
      "sweater's: 5\n",
      "midi-length: 2\n",
      "colorwise: 2\n",
      "wrinkle-prone: 2\n",
      "hoxton: 4\n",
      "boatneck: 4\n",
      "under-slip: 2\n",
      "nephew's: 2\n",
      "maternity-like: 3\n",
      "stevie's: 7\n",
      "poncho-like: 2\n",
      "unseamed: 2\n",
      "soft-looking: 2\n",
      "low-waisted: 2\n",
      "tunic-like: 2\n",
      "bra-straps: 2\n",
      "blousing: 3\n",
      "money's: 2\n",
      "slig: 2\n",
      "bell-sleeve: 2\n",
      "might've: 2\n",
      "siyu: 2\n",
      "skin-toned: 3\n",
      "polkadots: 2\n",
      "off-shoulder: 2\n",
      "else's: 2\n",
      "fully-lined: 2\n",
      "loose-fit: 2\n",
      "son's: 4\n",
      "carissima: 3\n",
      "poncho-type: 2\n",
      "someone's: 5\n",
      "boat-neck: 2\n",
      "missoni: 3\n",
      "petite-sized: 2\n",
      "t-back: 3\n",
      "mauvish: 2\n",
      "who've: 2\n",
      "skirt's: 2\n",
      "a-kind: 2\n",
      "birkenstocks: 4\n",
      "torsoed: 2\n",
      "everleigh: 2\n",
      "amadi: 3\n",
      "non-maternity: 2\n",
      "pant's: 2\n",
      "bomber-style: 2\n",
      "hipline: 2\n",
      "wedding-ish: 2\n",
      "slouchier: 3\n",
      "hook-and: 2\n",
      "that'd: 2\n",
      "people's: 2\n",
      "dryclean: 2\n",
      "poofiness: 2\n",
      "pullover's: 2\n",
      "non-stretchy: 3\n",
      "dolman-style: 2\n",
      "super-sale: 3\n",
      "g's: 2\n",
      "hei-hei: 2\n",
      "inseams: 2\n",
      "farrah: 2\n",
      "boy-leg: 2\n",
      "joe's: 2\n",
      "terrycloth-like: 2\n",
      "material's: 2\n",
      "artist's: 2\n",
      "bluishgreen: 2\n",
      "cross-wrap: 2\n"
     ]
    }
   ],
   "source": [
    "missing = Counter( \n",
    "    tok \n",
    "    for review in tokenized_reviews \n",
    "    for tok in review \n",
    "    if tok not in ft_model \n",
    ") \n",
    "\n",
    "print(\"Top OOV tokens:\", missing.most_common(10))\n",
    "print(\"All missing tokens:\")\n",
    "for token, count in missing.items():\n",
    "    print(f\"{token}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon reviewing the missing tokens, we found that most are either **misspellings/variants** (e.g., `swtr`, `flowey`) or **tokens with apostrophes** (e.g., `\"would've\"`, `\"model's\"`), which FastText doesn’t always match directly.  \n",
    "\n",
    "Since the OOV rate is very low and the unmatched tokens are not critical, we decided not to apply extra corrections or manual filtering. The model already provides strong coverage, making it reliable enough for embedding generation as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Generate Unweighted FastText Embedding\n",
    "\n",
    "Our first embedding-based representation is the **unweighted average of word vectors**.  \n",
    "In this approach, each review is turned into a single vector by averaging the embeddings of its tokens:  \n",
    "\n",
    "- For each token, we check if it exists in the FastText model.  \n",
    "- If it does, we collect its 300-dimensional vector.  \n",
    "- We then take the simple average of all vectors in that review.  \n",
    "- If a review has no known tokens, we assign a zero vector of the same dimension.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_embedding(tokens, model):\n",
    "    vectors = [model[w] for w in tokens if w in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "unweighted_embeds = np.array([avg_embedding(tokens, ft_model) for tokens in tokenized_reviews])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us one fixed-size vector per review, offering a simple way to capture the overall semantic meaning of the text without applying any weighting.  \n",
    "\n",
    "To verify the output, we preview the first few embedding values from a sample review using FastText.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText token-wise vectors (first 8 dims, showing up to 5 tokens):\n",
      "\n",
      "armhole: [-0.0017, -0.0550, -0.0264, -0.0018, -0.0155, -0.0128, 0.0309, -0.0929]\n",
      "bit: [-0.0609, -0.0703, -0.0337, 0.1412, -0.0352, 0.0791, 0.0059, -0.1402]\n",
      "oversized: [-0.0013, 0.0522, -0.0133, -0.0303, 0.0218, -0.0285, -0.0024, -0.0897]\n",
      "older: [-0.0147, 0.0463, -0.0061, 0.0066, -0.0126, 0.0617, -0.0522, -0.0952]\n",
      "woman: [-0.0890, 0.0070, 0.0440, 0.0096, -0.0066, 0.0220, 0.0380, -0.1163]\n"
     ]
    }
   ],
   "source": [
    "def validator_token_embeddings(tokens, ft_model, dims=5, limit=5):\n",
    "    print(f\"FastText token-wise vectors (first {dims} dims, showing up to {limit} tokens):\\n\")\n",
    "    shown = 0\n",
    "    for token in tokens:\n",
    "        if token in ft_model:\n",
    "            vec = ft_model[token][:dims]\n",
    "            rounded = [f\"{v:.4f}\" for v in vec]\n",
    "            print(f\"{token}: [{', '.join(rounded)}]\")\n",
    "            shown += 1\n",
    "        else:\n",
    "            print(f\"{token}: [OOV]\")\n",
    "            shown += 1\n",
    "        if shown >= limit:\n",
    "            break\n",
    "\n",
    "test_idx = 42\n",
    "validator_token_embeddings(tokenized_reviews[test_idx], ft_model, dims=8, limit=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sample output from review index 42, showing the first 8 dimensions of 5 token vectors.  \n",
    "All selected tokens are successfully recognized and mapped to meaningful embeddings.  \n",
    "\n",
    "This confirms that the embeddings are being computed as expected. With this validation, we can now move on to the next step.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Generate TF-IDF Weighted FastText Embedding\n",
    "\n",
    "We now improve on the simple averaging method by applying **TF-IDF weighting** to the word embeddings.  \n",
    "This gives more importance to informative words while downplaying very common ones.  \n",
    "\n",
    "Concept Overview:  \n",
    "- Compute TF-IDF values for all tokens using the vocabulary from Task 1.  \n",
    "- For each review, retrieve FastText embeddings for tokens that exist in both the model and TF-IDF dictionary.  \n",
    "- Scale each word vector by its TF-IDF weight.  \n",
    "- Take the weighted average of these vectors to form the final review embedding.  \n",
    "- If a review has no matching tokens, assign a zero vector of the same dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use same vocab as before\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocab)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(reviews)\n",
    "idf_weights = dict(zip(tfidf_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_))\n",
    "\n",
    "def tfidf_weighted_embedding(tokens, model, idf_dict):\n",
    "    vectors = []\n",
    "    weights = []\n",
    "    for token in tokens:\n",
    "        if token in model and token in idf_dict:\n",
    "            vectors.append(model[token] * idf_dict[token])\n",
    "            weights.append(idf_dict[token])\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.sum(vectors, axis=0) / np.sum(weights)\n",
    "\n",
    "weighted_embeds = np.array([\n",
    "    tfidf_weighted_embedding(tokens, ft_model, idf_weights)\n",
    "    for tokens in tokenized_reviews\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This weighted representation captures both the semantic meaning of words and their relative importance across the reviews, making it a stronger candidate for classification.  \n",
    "\n",
    "To validate the output, we preview a few token embeddings alongside their corresponding TF-IDF weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Weighted token-wise vectors (first 8 dims, up to 5 tokens):\n",
      "\n",
      "armhole: [-0.0096, -0.3115, -0.1492, -0.0103, -0.0876, -0.0726, 0.1749, -0.5260]  (weight: 5.6602)\n",
      "bit: [-0.1914, -0.2207, -0.1059, 0.4434, -0.1105, 0.2485, 0.0187, -0.4404]  (weight: 3.1410)\n",
      "oversized: [-0.0072, 0.2858, -0.0728, -0.1658, 0.1196, -0.1559, -0.0131, -0.4908]  (weight: 5.4743)\n",
      "older: [-0.1107, 0.3498, -0.0460, 0.0501, -0.0951, 0.4661, -0.3941, -0.7189]  (weight: 7.5538)\n",
      "woman: [-0.4862, 0.0383, 0.2401, 0.0524, -0.0360, 0.1200, 0.2076, -0.6353]  (weight: 5.4610)\n"
     ]
    }
   ],
   "source": [
    "def validator_weighted_tokens(tokens, model, idf_dict, dims=5, limit=5):\n",
    "    print(f\"TF-IDF Weighted token-wise vectors (first {dims} dims, up to {limit} tokens):\\n\")\n",
    "    shown = 0\n",
    "    for token in tokens:\n",
    "        if token in model and token in idf_dict:\n",
    "            vec = model[token] * idf_dict[token]\n",
    "            rounded = [f\"{v:.4f}\" for v in vec[:dims]]\n",
    "            print(f\"{token}: [{', '.join(rounded)}]  (weight: {idf_dict[token]:.4f})\")\n",
    "            shown += 1\n",
    "        elif token in model:\n",
    "            print(f\"{token}: [valid token, missing IDF]\")\n",
    "            shown += 1\n",
    "        else:\n",
    "            print(f\"{token}: [OOV]\")\n",
    "            shown += 1\n",
    "        if shown >= limit:\n",
    "            break\n",
    "\n",
    "test_idx = 42\n",
    "validator_weighted_tokens(tokenized_reviews[test_idx], ft_model, idf_weights, dims=8, limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing the output, the embeddings appear to be correctly computed. We will now proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Save Outputs\n",
    "\n",
    "After generating the three types of document-level representations, we save them in the required output formats.  \n",
    "Each line in these files corresponds to a single review, starting with `#index` followed by the feature values separated by commas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Bag-of-Words\n",
    "\n",
    "- Saves the sparse Bag-of-Words representation to `count_vectors.txt`  \n",
    "- Format: `#reviewIndex,tokenIndex1:count1,tokenIndex2:count2,...`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sparse BoW counts\n",
    "with open(\"../output/count_vectors.txt\", \"w\") as f:\n",
    "    for i, row in enumerate(X_counts):\n",
    "        entries = [\n",
    "            f\"{idx}:{val}\"\n",
    "            for idx, val in zip(row.indices, row.data)\n",
    "        ]\n",
    "        f.write(f\"#\" + str(i) + \",\" + \",\".join(entries) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Unweighted Embeddings  \n",
    "\n",
    "- Saves the average FastText embeddings to `unweighted_vectors.txt`  \n",
    "- Format: `#reviewIndex,val1,val2,...,val300`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unweighted FastText embeddings\n",
    "with open(\"../output/unweighted_vectors.txt\", \"w\") as f:\n",
    "    for i, vec in enumerate(unweighted_embeds):\n",
    "        vec_str = \",\".join(map(str, vec))\n",
    "        f.write(f\"#{i},{vec_str}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Weighted Embeddings  \n",
    "\n",
    "- Saves the TF-IDF weighted FastText embeddings to `weighted_vectors.txt`  \n",
    "- Format: `#reviewIndex,val1,val2,...,val300`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weighted FastText embeddings\n",
    "with open(\"../output/weighted_vectors.txt\", \"w\") as f:\n",
    "    for i, vec in enumerate(weighted_embeds):\n",
    "        vec_str = \",\".join(map(str, vec))\n",
    "        f.write(f\"#{i},{vec_str}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection, the file format meets all specified requirements and appears correctly structured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Clothing Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Target Variable Examination\n",
    "Before going into this task, we would like to examining the target variable in dataset before we feed it into our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = \"../output/processed.csv\"\n",
    "VOCAB_PATH = \"../output/vocab.txt\"\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>review_length</th>\n",
       "      <th>processed_tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>98</td>\n",
       "      <td>['high', 'hope', 'wanted', 'work', 'initially'...</td>\n",
       "      <td>high hope wanted work initially petite usual f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>22</td>\n",
       "      <td>['jumpsuit', 'fun', 'flirty', 'fabulous', 'tim...</td>\n",
       "      <td>jumpsuit fun flirty fabulous time compliment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>36</td>\n",
       "      <td>['shirt', 'due', 'adjustable', 'front', 'tie',...</td>\n",
       "      <td>shirt due adjustable front tie length legging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>98</td>\n",
       "      <td>['tracy', 'reese', 'dress', 'petite', 'foot', ...</td>\n",
       "      <td>tracy reese dress petite foot tall brand prett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>101</td>\n",
       "      <td>['basket', 'hte', 'person', 'store', 'pick', '...</td>\n",
       "      <td>basket hte person store pick teh pale hte gorg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "0         1077   60  Some major design flaws   \n",
       "1         1049   50         My favorite buy!   \n",
       "2          847   47         Flattering shirt   \n",
       "3         1080   49  Not for the very petite   \n",
       "4          858   39     Cagrcoal shimmer fun   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  I had such high hopes for this dress and reall...       3                0   \n",
       "1  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "2  This shirt is very flattering to all due to th...       5                1   \n",
       "3  I love tracy reese dresses, but this one is no...       2                0   \n",
       "4  I aded this in my basket at hte last mintue to...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \\\n",
       "0                        0         General         Dresses    Dresses   \n",
       "1                        0  General Petite         Bottoms      Pants   \n",
       "2                        6         General            Tops    Blouses   \n",
       "3                        4         General         Dresses    Dresses   \n",
       "4                        1  General Petite            Tops      Knits   \n",
       "\n",
       "   review_length                                   processed_tokens  \\\n",
       "0             98  ['high', 'hope', 'wanted', 'work', 'initially'...   \n",
       "1             22  ['jumpsuit', 'fun', 'flirty', 'fabulous', 'tim...   \n",
       "2             36  ['shirt', 'due', 'adjustable', 'front', 'tie',...   \n",
       "3             98  ['tracy', 'reese', 'dress', 'petite', 'foot', ...   \n",
       "4            101  ['basket', 'hte', 'person', 'store', 'pick', '...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  high hope wanted work initially petite usual f...  \n",
       "1       jumpsuit fun flirty fabulous time compliment  \n",
       "2  shirt due adjustable front tie length legging ...  \n",
       "3  tracy reese dress petite foot tall brand prett...  \n",
       "4  basket hte person store pick teh pale hte gorg...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has already been processed in Task 1, so here we focus only on the target label, `Recommended IND`.  \n",
    "\n",
    "Our first step is to check if the column is valid:  \n",
    "- It should contain only `0` and `1` values.  \n",
    "- Its data type should be integer.  \n",
    "\n",
    "This quick validation ensures the labels are ready to be used for model training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Recommended IND': [0 1]\n",
      "Contains only 0 and 1: True\n",
      "Is integer type: True\n",
      "'Recommended IND' column is valid.\n"
     ]
    }
   ],
   "source": [
    "unique_values = df['Recommended IND'].unique()\n",
    "is_binary = set(unique_values).issubset({0, 1})\n",
    "is_integer = pd.api.types.is_integer_dtype(df['Recommended IND'])\n",
    "\n",
    "print(f\"Unique values in 'Recommended IND': {unique_values}\")\n",
    "print(f\"Contains only 0 and 1: {is_binary}\")\n",
    "print(f\"Is integer type: {is_integer}\")\n",
    "\n",
    "if is_binary and is_integer:\n",
    "    print(\"'Recommended IND' column is valid.\")\n",
    "else:\n",
    "    print(\"'Recommended IND' column is invalid. Please check the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first check confirms that the target column is valid.  \n",
    "Next, we examine whether there are any **missing values** in `Recommended IND`.  \n",
    "This helps us ensure that every review has a label before moving on to modeling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'Recommended IND': 0\n",
      "No missing labels found in the 'Recommended IND' column.\n"
     ]
    }
   ],
   "source": [
    "missing_count = df['Recommended IND'].isnull().sum()\n",
    "print(f\"Number of missing values in 'Recommended IND': {missing_count}\")\n",
    "\n",
    "if missing_count > 0:\n",
    "    print(\"Warning: There are missing labels in the 'Recommended IND' column.\")\n",
    "else:\n",
    "    print(\"No missing labels found in the 'Recommended IND' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no missing labels detected, we now look at the **class distribution** of `Recommended IND`.  \n",
    "This shows how many reviews are marked as recommended (`1`) versus not recommended (`0`).  \n",
    "Understanding this balance is important, since class imbalance can affect model performance and the choice of evaluation metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "Recommended IND\n",
      "1    16077\n",
      "0     3575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage Distribution:\n",
      "Recommended IND\n",
      "1    81.808467\n",
      "0    18.191533\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "class_distribution = df['Recommended IND'].value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_distribution)\n",
    "print(\"\\nPercentage Distribution:\")\n",
    "print(class_distribution / class_distribution.sum() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution shows that out of ~19,600 reviews, **81.8%** are labeled as recommended (`1`) and **18.2%** as not recommended (`0`).  \n",
    "This confirms a noticeable class imbalance, which we need to keep in mind when selecting models and evaluation metrics.  \n",
    "\n",
    "To make this clearer, we plot the class distribution below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of the 'Recommended IND' column\n",
    "if 'Recommended IND' in df.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    df['Recommended IND'].value_counts().plot(kind='bar', color=['skyblue', 'orange'], edgecolor='black')\n",
    "    plt.title('Distribution of Recommended IND', fontsize=14)\n",
    "    plt.xlabel('Recommended IND', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'Recommended IND' column not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar chart highlights the imbalance in our target variable:  \n",
    "- The majority of reviews (~16,000) are **recommended** (`1`).  \n",
    "- A smaller portion (~3,600) are **not recommended** (`0`).  \n",
    "\n",
    "This confirms that the dataset is skewed toward positive recommendations (about 4:1 ratio).  \n",
    "We’ll need to keep this in mind when evaluating models, as accuracy alone may not fully reflect performance.  \n",
    "\n",
    "With the target variable examined and validated, we can now move on to **Question 1** and compare different feature representations with machine learning models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Question 1 — Which representation performs best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Baseline Models Experiement\n",
    "\n",
    "With the target validated, we now ask:  \n",
    "**Which feature representation from Task 2 works best with our models?**  \n",
    "\n",
    "We test three setups:  \n",
    "- **Bag-of-Words (Count vectors)**  \n",
    "- **Unweighted FastText embeddings**  \n",
    "- **TF-IDF Weighted FastText embeddings**  \n",
    "\n",
    "To handle class imbalance, we evaluate with multiple metrics (Accuracy, F1, ROC-AUC, Balanced Accuracy) under **Stratified 5-fold CV**.  \n",
    "We also extract the target vector `y` and confirm its shape and positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: (19652,)  | pos_rate: 0.8181\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Use multiple metrics — accuracy alone can be misleading under imbalance\n",
    "scoring = {\n",
    "    \"acc\": \"accuracy\",\n",
    "    \"f1\": \"f1\",\n",
    "    \"roc\": \"roc_auc\",\n",
    "    \"bacc\": \"balanced_accuracy\"\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Target vector (ensure 0/1 int)\n",
    "y = df[\"Recommended IND\"].astype(int).to_numpy()\n",
    "print(\"y shape:\", y.shape, \" | pos_rate:\", np.mean(y).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the feature representations generated in **Task 2**.  \n",
    "- **BoW (Count vectors)** are stored in `count_vectors.txt` (sparse format).  \n",
    "- **Unweighted FastText embeddings** in `unweighted_vectors.txt`.  \n",
    "- **TF-IDF Weighted FastText embeddings** in `weighted_vectors.txt`.  \n",
    "\n",
    "We define helper functions to parse these files into proper matrices (sparse for BoW, dense for embeddings).  \n",
    "After loading, we check the shapes of all three feature sets and ensure they align with the target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 6548\n",
      "Shapes -> BoW: (19652, 6548)  | Unweighted: (19652, 300)  | Weighted: (19652, 300)\n"
     ]
    }
   ],
   "source": [
    "VOCAB_PATH = \"../output/vocab.txt\"\n",
    "COUNT_VECTORS_PATH = \"../output/count_vectors.txt\"\n",
    "UNW_PATH = \"../output/unweighted_vectors.txt\"\n",
    "W_PATH   = \"../output/weighted_vectors.txt\"\n",
    "\n",
    "# Load vocab size\n",
    "with open(VOCAB_PATH, \"r\") as f:\n",
    "    vocab_size = sum(1 for _ in f)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "def load_sparse_counts(path, n_features):\n",
    "    # Parse lines like: \"#12,3:2,10:1,41:4\"\n",
    "    indices = []\n",
    "    indptr = [0]\n",
    "    data = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            # parts[0] is like \"#12\"\n",
    "            for kv in parts[1:]:\n",
    "                k, v = kv.split(\":\")\n",
    "                indices.append(int(k))\n",
    "                data.append(float(v))\n",
    "            indptr.append(len(indices))\n",
    "    X = csr_matrix((np.array(data, dtype=np.float32),\n",
    "                    np.array(indices, dtype=np.int32),\n",
    "                    np.array(indptr, dtype=np.int32)),\n",
    "                   shape=(len(indptr)-1, n_features))\n",
    "    return X\n",
    "\n",
    "def load_dense_vectors(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            # \"#idx,val1,val2,...\"\n",
    "            line = line.strip()\n",
    "            comma = line.find(\",\")\n",
    "            vec_str = line[comma+1:]\n",
    "            rows.append([float(x) for x in vec_str.split(\",\")])\n",
    "    return np.asarray(rows, dtype=np.float32)\n",
    "\n",
    "# Load all three\n",
    "X_bow = load_sparse_counts(COUNT_VECTORS_PATH, vocab_size)\n",
    "X_unw = load_dense_vectors(UNW_PATH)\n",
    "X_w   = load_dense_vectors(W_PATH)\n",
    "\n",
    "print(\"Shapes -> BoW:\", X_bow.shape, \" | Unweighted:\", X_unw.shape, \" | Weighted:\", X_w.shape)\n",
    "\n",
    "# Sanity: all representations must align in rows with y\n",
    "assert X_bow.shape[0] == y.shape[0] == X_unw.shape[0] == X_w.shape[0], \"Row mismatch among features/target.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before testing real models, we establish a **baseline** using a `DummyClassifier` that always predicts the most frequent class.  \n",
    "This gives us a reference point: any meaningful model should perform better than this trivial strategy.  \n",
    "\n",
    "We evaluate the dummy model with the same cross-validation setup and metrics (Accuracy, F1, ROC-AUC, Balanced Accuracy) to provide a fair comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.818085</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.899941</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacc</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std\n",
       "metric                    \n",
       "acc     0.818085  0.000023\n",
       "f1      0.899941  0.000014\n",
       "roc     0.500000  0.000000\n",
       "bacc    0.500000  0.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_STATE)\n",
    "base_res = cross_validate(baseline, X_bow, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"metric\": list(scoring.keys()),\n",
    "    \"mean\": [base_res[f\"test_{k}\"].mean() for k in scoring.keys()],\n",
    "    \"std\":  [base_res[f\"test_{k}\"].std()  for k in scoring.keys()],\n",
    "}).set_index(\"metric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model achieves **81.8% accuracy**, which simply reflects the majority class rate in the dataset.  \n",
    "However, its **ROC-AUC (0.5)** and **Balanced Accuracy (0.5)** show it has no real predictive power.  \n",
    "The **F1 score (0.90)** is also misleading here, as it comes entirely from predicting the majority class.  \n",
    "\n",
    "This confirms that accuracy and F1 alone can be deceptive under imbalance — stronger models need to show gains in ROC-AUC and Balanced Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we evaluate a stronger baseline model: **Logistic Regression** with class weights set to `\"balanced\"`.  \n",
    "This adjustment compensates for the skewed class distribution by giving more weight to the minority class.  \n",
    "\n",
    "We test Logistic Regression on all three feature sets:  \n",
    "- **BoW (Count vectors)** — used directly without scaling.  \n",
    "- **Unweighted embeddings** — scaled before training.  \n",
    "- **TF-IDF Weighted embeddings** — also scaled before training.  \n",
    "\n",
    "Each pipeline is run with 5-fold cross-validation, and we record the mean and standard deviation for all evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature set</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>mean_roc</th>\n",
       "      <th>mean_bacc</th>\n",
       "      <th>std_acc</th>\n",
       "      <th>std_f1</th>\n",
       "      <th>std_roc</th>\n",
       "      <th>std_bacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoW (Count)</td>\n",
       "      <td>0.849634</td>\n",
       "      <td>0.904821</td>\n",
       "      <td>0.888111</td>\n",
       "      <td>0.807387</td>\n",
       "      <td>0.005688</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.005601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emb (Unweighted Avg)</td>\n",
       "      <td>0.795950</td>\n",
       "      <td>0.864852</td>\n",
       "      <td>0.870756</td>\n",
       "      <td>0.791652</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.006890</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.008212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emb (TF-IDF Weighted)</td>\n",
       "      <td>0.784349</td>\n",
       "      <td>0.856635</td>\n",
       "      <td>0.860131</td>\n",
       "      <td>0.778144</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.008550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature set  mean_acc   mean_f1  mean_roc  mean_bacc   std_acc  \\\n",
       "0            BoW (Count)  0.849634  0.904821  0.888111   0.807387  0.005688   \n",
       "1   Emb (Unweighted Avg)  0.795950  0.864852  0.870756   0.791652  0.008911   \n",
       "2  Emb (TF-IDF Weighted)  0.784349  0.856635  0.860131   0.778144  0.010062   \n",
       "\n",
       "     std_f1   std_roc  std_bacc  \n",
       "0  0.003916  0.005595  0.005601  \n",
       "1  0.006890  0.003354  0.008212  \n",
       "2  0.007716  0.004239  0.008550  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Pipelines per feature set\n",
    "pipe_bow = Pipeline([\n",
    "    (\"clf\", logreg)  # no scaler for sparse BoW\n",
    "])\n",
    "\n",
    "pipe_unw = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", logreg)\n",
    "])\n",
    "\n",
    "pipe_w = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", logreg)\n",
    "])\n",
    "\n",
    "def eval_pipe(name, pipe, X, y):\n",
    "    res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "    row = {\n",
    "        \"Feature set\": name,\n",
    "        **{f\"mean_{m}\": res[f\"test_{m}\"].mean() for m in scoring.keys()},\n",
    "        **{f\"std_{m}\":  res[f\"test_{m}\"].std()  for m in scoring.keys()},\n",
    "    }\n",
    "    return row\n",
    "\n",
    "results = []\n",
    "results.append(eval_pipe(\"BoW (Count)\",             pipe_bow, X_bow, y))\n",
    "results.append(eval_pipe(\"Emb (Unweighted Avg)\",    pipe_unw, X_unw, y))\n",
    "results.append(eval_pipe(\"Emb (TF-IDF Weighted)\",   pipe_w,   X_w,   y))\n",
    "\n",
    "df_q1 = pd.DataFrame(results).sort_values(\"mean_f1\", ascending=False).reset_index(drop=True)\n",
    "df_q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show clear differences across feature representations:  \n",
    "\n",
    "- **BoW (Count)** performs best overall, with the highest **F1 (0.905)** and **ROC-AUC (0.888)**, while also maintaining strong balanced accuracy (~0.81).  \n",
    "- **Unweighted embeddings** achieve decent performance (**F1 = 0.865**, **ROC-AUC = 0.871**) but fall short compared to BoW.  \n",
    "- **TF-IDF weighted embeddings** perform slightly worse than unweighted, with **F1 = 0.857** and **ROC-AUC = 0.860**.  \n",
    "\n",
    "Overall, Logistic Regression favors the **BoW representation**, which outperforms embedding-based approaches on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complement Logistic Regression, we now test a **Linear Support Vector Machine (LinearSVC)** with class weights set to `\"balanced\"`.  \n",
    "Like before, we run experiments on all three feature sets:  \n",
    "\n",
    "- **BoW (Count vectors)** — directly used without scaling.  \n",
    "- **Unweighted embeddings** — scaled before training.  \n",
    "- **TF-IDF Weighted embeddings** — scaled before training.  \n",
    "\n",
    "We apply 5-fold cross-validation and collect the same evaluation metrics to compare against the Logistic Regression results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature set</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>mean_roc</th>\n",
       "      <th>mean_bacc</th>\n",
       "      <th>std_acc</th>\n",
       "      <th>std_f1</th>\n",
       "      <th>std_roc</th>\n",
       "      <th>std_bacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoW (Count) + SVM</td>\n",
       "      <td>0.835691</td>\n",
       "      <td>0.896807</td>\n",
       "      <td>0.850525</td>\n",
       "      <td>0.770806</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>0.007464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emb (Unweighted Avg) + SVM</td>\n",
       "      <td>0.794322</td>\n",
       "      <td>0.863679</td>\n",
       "      <td>0.870790</td>\n",
       "      <td>0.790113</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.008167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emb (TF-IDF Weighted) + SVM</td>\n",
       "      <td>0.783534</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.860363</td>\n",
       "      <td>0.778082</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.009002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature set  mean_acc   mean_f1  mean_roc  mean_bacc  \\\n",
       "0            BoW (Count) + SVM  0.835691  0.896807  0.850525   0.770806   \n",
       "1   Emb (Unweighted Avg) + SVM  0.794322  0.863679  0.870790   0.790113   \n",
       "2  Emb (TF-IDF Weighted) + SVM  0.783534  0.855966  0.860363   0.778082   \n",
       "\n",
       "    std_acc    std_f1   std_roc  std_bacc  \n",
       "0  0.002954  0.002149  0.005672  0.007464  \n",
       "1  0.008221  0.006389  0.003553  0.008167  \n",
       "2  0.010962  0.008438  0.004387  0.009002  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "\n",
    "pipe_bow_svm = Pipeline([(\"clf\", svm)])\n",
    "pipe_unw_svm = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", svm)])\n",
    "pipe_w_svm   = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", svm)])\n",
    "\n",
    "svm_rows = []\n",
    "svm_rows.append(eval_pipe(\"BoW (Count) + SVM\",           pipe_bow_svm, X_bow, y))\n",
    "svm_rows.append(eval_pipe(\"Emb (Unweighted Avg) + SVM\",  pipe_unw_svm, X_unw, y))\n",
    "svm_rows.append(eval_pipe(\"Emb (TF-IDF Weighted) + SVM\", pipe_w_svm,   X_w,   y))\n",
    "\n",
    "df_q1_svm = pd.DataFrame(svm_rows).sort_values(\"mean_f1\", ascending=False).reset_index(drop=True)\n",
    "df_q1_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Linear SVM results show a similar trend to Logistic Regression:  \n",
    "\n",
    "- **BoW (Count)** again comes out on top, with the highest **F1 (0.897)** and strong accuracy (~0.836), though its ROC-AUC (0.851) is lower than Logistic Regression.  \n",
    "- **Unweighted embeddings** achieve competitive **ROC-AUC (0.871)**, nearly matching their Logistic Regression performance.  \n",
    "- **TF-IDF weighted embeddings** perform slightly worse, with **F1 = 0.856** and **ROC-AUC = 0.860**.  \n",
    "\n",
    "Overall, SVM reinforces the finding that **BoW is the strongest representation**, while embeddings (especially unweighted) still perform reasonably well but lag behind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if oversampling can help, we apply **SMOTE (Synthetic Minority Oversampling Technique)** on the minority class before training Logistic Regression.  \n",
    "Unlike the earlier balanced-class-weight approach, this version of Logistic Regression uses **no class weights** and instead relies on SMOTE to balance the training data.  \n",
    "We test this setup on the **Unweighted FastText embeddings** and evaluate it with the same cross-validation and metrics as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.007080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.869802</td>\n",
       "      <td>0.005399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.868127</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacc</th>\n",
       "      <td>0.788377</td>\n",
       "      <td>0.006397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std\n",
       "metric                    \n",
       "acc     0.801802  0.007080\n",
       "f1      0.869802  0.005399\n",
       "roc     0.868127  0.004110\n",
       "bacc    0.788377  0.006397"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_smote = LogisticRegression(\n",
    "    max_iter=2000, class_weight=None, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe_unw_smote = ImbPipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "    (\"clf\", logreg_smote)\n",
    "])\n",
    "\n",
    "res_smote = cross_validate(pipe_unw_smote, X_unw, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "pd.DataFrame({\n",
    "    \"metric\": list(scoring.keys()),\n",
    "    \"mean\": [res_smote[f\"test_{k}\"].mean() for k in scoring.keys()],\n",
    "    \"std\":  [res_smote[f\"test_{k}\"].std()  for k in scoring.keys()],\n",
    "}).set_index(\"metric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE-based Logistic Regression achieves **Accuracy = 80.2%**, **F1 = 0.870**, and **ROC-AUC = 0.868**, with **Balanced Accuracy = 0.788**.  \n",
    "Compared to the class-weighted Logistic Regression results, the scores are similar but not clearly better — SMOTE provides only a modest benefit.  \n",
    "This suggests that while SMOTE can balance the classes, the **class-weighting strategy is already effective**, and additional oversampling does not significantly improve performance here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the results easier to compare, we tidy up the outputs from both **Logistic Regression** and **Linear SVM**.  \n",
    "We standardize the column names, keep only the key metrics (F1, ROC-AUC, Balanced Accuracy, Accuracy), and merge everything into a single table.  \n",
    "\n",
    "This combined view lets us directly compare how each feature representation performs across the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature set</th>\n",
       "      <th>Model</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>mean_roc_auc</th>\n",
       "      <th>mean_bacc</th>\n",
       "      <th>mean_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoW (Count) + SVM</td>\n",
       "      <td>LinearSVC (balanced)</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.7708</td>\n",
       "      <td>0.8357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emb (Unweighted Avg) + SVM</td>\n",
       "      <td>LinearSVC (balanced)</td>\n",
       "      <td>0.8637</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.7943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emb (TF-IDF Weighted) + SVM</td>\n",
       "      <td>LinearSVC (balanced)</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.7835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BoW (Count)</td>\n",
       "      <td>LogReg (balanced)</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.8881</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emb (Unweighted Avg)</td>\n",
       "      <td>LogReg (balanced)</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.7960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emb (TF-IDF Weighted)</td>\n",
       "      <td>LogReg (balanced)</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.7843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature set                 Model  mean_f1  mean_roc_auc  \\\n",
       "0            BoW (Count) + SVM  LinearSVC (balanced)   0.8968        0.8505   \n",
       "1   Emb (Unweighted Avg) + SVM  LinearSVC (balanced)   0.8637        0.8708   \n",
       "2  Emb (TF-IDF Weighted) + SVM  LinearSVC (balanced)   0.8560        0.8604   \n",
       "3                  BoW (Count)     LogReg (balanced)   0.9048        0.8881   \n",
       "4         Emb (Unweighted Avg)     LogReg (balanced)   0.8649        0.8708   \n",
       "5        Emb (TF-IDF Weighted)     LogReg (balanced)   0.8566        0.8601   \n",
       "\n",
       "   mean_bacc  mean_acc  \n",
       "0     0.7708    0.8357  \n",
       "1     0.7901    0.7943  \n",
       "2     0.7781    0.7835  \n",
       "3     0.8074    0.8496  \n",
       "4     0.7917    0.7960  \n",
       "5     0.7781    0.7843  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tidy(df, model_name):\n",
    "    use = df.copy()\n",
    "    use.insert(1, \"Model\", model_name)\n",
    "    # Normalize possible column names\n",
    "    if \"mean_roc\" in use.columns and \"mean_roc_auc\" not in use.columns:\n",
    "        use = use.rename(columns={\"mean_roc\": \"mean_roc_auc\"})\n",
    "    # Keep only columns that exist\n",
    "    keep_cols = [\"Feature set\", \"Model\", \"mean_f1\", \"mean_roc_auc\", \"mean_bacc\", \"mean_acc\"]\n",
    "    keep_cols = [c for c in keep_cols if c in use.columns]\n",
    "    return use[keep_cols]\n",
    "\n",
    "tbl = pd.concat(\n",
    "    [\n",
    "        tidy(df_q1, \"LogReg (balanced)\"),\n",
    "        tidy(df_q1_svm, \"LinearSVC (balanced)\"),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# Round for neatness\n",
    "num_cols = [c for c in tbl.columns if c.startswith(\"mean_\")]\n",
    "tbl[num_cols] = tbl[num_cols].round(4)\n",
    "\n",
    "# Sort by model then F1 desc if available\n",
    "sort_cols = [\"Model\"] + ([ \"mean_f1\" ] if \"mean_f1\" in tbl.columns else [])\n",
    "tbl = tbl.sort_values(sort_cols, ascending=[True, False] if sort_cols else True).reset_index(drop=True)\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This summary table confirms the earlier trends:  \n",
    "\n",
    "- **BoW (Count)** remains the strongest representation overall.  \n",
    "  - With **Logistic Regression**, it achieves the best balance of metrics (**F1 = 0.905**, **ROC-AUC = 0.888**, **Balanced Accuracy = 0.807**).  \n",
    "  - With **SVM**, BoW still performs well (**F1 = 0.897**), though its ROC-AUC is lower than with Logistic Regression.  \n",
    "\n",
    "- **Unweighted embeddings** are competitive in terms of ROC-AUC (~0.871 for both models) but slightly weaker on F1 and accuracy.  \n",
    "\n",
    "- **TF-IDF weighted embeddings** consistently trail behind unweighted embeddings, regardless of model.  \n",
    "\n",
    "Overall, **BoW paired with Logistic Regression (balanced)** gives the most robust performance, while embeddings provide decent alternatives but do not surpass the simpler BoW representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare strategies for handling class imbalance, we directly test **Logistic Regression with class weights balanced** against **Logistic Regression with SMOTE oversampling**.  \n",
    "Both are evaluated on the **Unweighted FastText embeddings** using the same cross-validation and metrics.  \n",
    "This lets us see whether oversampling provides any advantage over the simpler class-weight adjustment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>Balanced (mean)</th>\n",
       "      <th>Balanced (std)</th>\n",
       "      <th>SMOTE (mean)</th>\n",
       "      <th>SMOTE (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.8018</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roc</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacc</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.0064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric  Balanced (mean)  Balanced (std)  SMOTE (mean)  SMOTE (std)\n",
       "0    acc           0.7960          0.0089        0.8018       0.0071\n",
       "1     f1           0.8649          0.0069        0.8698       0.0054\n",
       "2    roc           0.8708          0.0034        0.8681       0.0041\n",
       "3   bacc           0.7917          0.0082        0.7884       0.0064"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with class_weight balanced (already trained)\n",
    "res_balanced = cross_validate(\n",
    "    pipe_unw, X_unw, y, cv=cv, scoring=scoring, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Logistic Regression + SMOTE (already defined as pipe_unw_smote)\n",
    "res_smote = cross_validate(\n",
    "    pipe_unw_smote, X_unw, y, cv=cv, scoring=scoring, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Build comparison table\n",
    "comp = pd.DataFrame({\n",
    "    \"metric\": list(scoring.keys()),\n",
    "    \"Balanced (mean)\": [res_balanced[f\"test_{m}\"].mean() for m in scoring],\n",
    "    \"Balanced (std)\":  [res_balanced[f\"test_{m}\"].std()  for m in scoring],\n",
    "    \"SMOTE (mean)\":    [res_smote[f\"test_{m}\"].mean()    for m in scoring],\n",
    "    \"SMOTE (std)\":     [res_smote[f\"test_{m}\"].std()     for m in scoring],\n",
    "})\n",
    "\n",
    "comp = comp.round(4)\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison shows very similar results:  \n",
    "\n",
    "- **Balanced weights**: F1 = 0.865, ROC-AUC = 0.871, Balanced Accuracy = 0.792  \n",
    "- **SMOTE**: F1 = 0.870, ROC-AUC = 0.868, Balanced Accuracy = 0.788  \n",
    "\n",
    "SMOTE gives a slight bump in accuracy and F1, but its ROC-AUC and balanced accuracy are slightly worse.  \n",
    "Overall, the two approaches perform nearly the same, suggesting that **class weighting alone is already sufficient**, and SMOTE does not add a clear benefit for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Additional Models Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before experimenting with additional models, we reset the evaluation setup for clarity:  \n",
    "\n",
    "- Define the same metrics (**Accuracy, F1, ROC-AUC, Balanced Accuracy**)  \n",
    "- Use **Stratified 5-fold CV** with a fixed random seed for reproducibility  \n",
    "- Run sanity checks to ensure all three feature matrices (BoW, Unweighted, Weighted) align with the target vector `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes OK -> BoW: (19652, 6548) | Unweighted: (19652, 300) | Weighted: (19652, 300) | y: (19652,)\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5\n",
    "\n",
    "scoring = {\n",
    "    \"acc\": \"accuracy\",\n",
    "    \"f1\": \"f1\",\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"bacc\": \"balanced_accuracy\",\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Sanity checks\n",
    "assert X_bow.shape[0] == y.shape[0] == X_unw.shape[0] == X_w.shape[0], \"Rows mismatch among features/target.\"\n",
    "print(\"Shapes OK -> BoW:\", X_bow.shape, \"| Unweighted:\", X_unw.shape, \"| Weighted:\", X_w.shape, \"| y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output confirms that all matrices have consistent shapes, so we can safely proceed with further experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To streamline experiments with multiple classifiers, we define a helper function `evaluate_model`.  \n",
    "It takes the experiment name, a pipeline, and a feature set, then runs **5-fold cross-validation** with our chosen metrics.  \n",
    "\n",
    "The function returns a summary row containing the mean and standard deviation for each metric, making it easier to compare models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, pipeline, X, y, *, cv=cv, scoring=scoring):\n",
    "    res = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "    row = {\"Exp\": name}\n",
    "    for m in scoring:\n",
    "        row[f\"{m}_mean\"] = float(np.mean(res[f\"test_{m}\"]))\n",
    "        row[f\"{m}_std\"]  = float(np.std(res[f\"test_{m}\"]))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a broader set of models to compare across the three feature representations.  \n",
    "\n",
    "- **Sparse-friendly (BoW)**  \n",
    "  - Logistic Regression (balanced)  \n",
    "  - Linear SVM (balanced)  \n",
    "  - Multinomial Naive Bayes  \n",
    "  - Random Forest (balanced)  \n",
    "\n",
    "- **Dense-friendly (Embeddings)**  \n",
    "  - Logistic Regression (balanced)  \n",
    "  - Linear SVM (balanced)  \n",
    "  - Histogram-based Gradient Boosting (balanced)  \n",
    "  - Multi-Layer Perceptron (MLP) with 128 hidden units  \n",
    "\n",
    "This setup allows us to test both linear and non-linear models, covering simple baselines through more complex learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse-friendly (BoW)\n",
    "models_bow = {\n",
    "    \"LogReg (balanced)\": LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    \"LinearSVC (balanced)\": LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"RandomForest (balanced)\": RandomForestClassifier(\n",
    "        n_estimators=250, max_depth=None, class_weight=\"balanced\",\n",
    "        n_jobs=-1, random_state=RANDOM_STATE\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Dense-friendly (Embeddings)\n",
    "models_dense = {\n",
    "    \"LogReg (balanced)\": LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    \"LinearSVC (balanced)\": LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "    \"HistGB (balanced)\": HistGradientBoostingClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\"),\n",
    "    \"MLP (128)\": MLPClassifier(hidden_layer_sizes=(128,), max_iter=80, random_state=RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model set defined, we now run each classifier across all feature representations.  \n",
    "\n",
    "- For **BoW**, we keep the sparse format and feed it directly into the models.  \n",
    "- For **embeddings**, we scale the dense vectors before training.  \n",
    "\n",
    "Using the `evaluate_model` helper, we collect the mean and standard deviation for each metric under 5-fold CV.  \n",
    "Finally, we combine the results into a single dataframe and sort by **F1 score** to highlight the top-performing setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exp</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>bacc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB + BoW</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.7929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest (balanced) + BoW</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>0.6492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP (128) + Emb-Unweighted</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>0.7108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogReg (balanced) + BoW</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.8881</td>\n",
       "      <td>0.8074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP (128) + Emb-WeightedTFIDF</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>0.7055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC (balanced) + BoW</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.7708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGB (balanced) + Emb-WeightedTFIDF</td>\n",
       "      <td>0.8121</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.7359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGB (balanced) + Emb-Unweighted</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>0.8422</td>\n",
       "      <td>0.7449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogReg (balanced) + Emb-Unweighted</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.7917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearSVC (balanced) + Emb-Unweighted</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.8637</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.7901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg (balanced) + Emb-WeightedTFIDF</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearSVC (balanced) + Emb-WeightedTFIDF</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Exp  acc_mean  f1_mean  roc_auc_mean  \\\n",
       "0                        MultinomialNB + BoW    0.8742   0.9229        0.8995   \n",
       "1              RandomForest (balanced) + BoW    0.8594   0.9193        0.8906   \n",
       "2                 MLP (128) + Emb-Unweighted    0.8440   0.9061        0.8378   \n",
       "3                    LogReg (balanced) + BoW    0.8496   0.9048        0.8881   \n",
       "4              MLP (128) + Emb-WeightedTFIDF    0.8389   0.9029        0.8303   \n",
       "5                 LinearSVC (balanced) + BoW    0.8357   0.8968        0.8505   \n",
       "6      HistGB (balanced) + Emb-WeightedTFIDF    0.8121   0.8817        0.8330   \n",
       "7         HistGB (balanced) + Emb-Unweighted    0.8125   0.8813        0.8422   \n",
       "8         LogReg (balanced) + Emb-Unweighted    0.7960   0.8649        0.8708   \n",
       "9      LinearSVC (balanced) + Emb-Unweighted    0.7943   0.8637        0.8708   \n",
       "10     LogReg (balanced) + Emb-WeightedTFIDF    0.7843   0.8566        0.8601   \n",
       "11  LinearSVC (balanced) + Emb-WeightedTFIDF    0.7835   0.8560        0.8604   \n",
       "\n",
       "    bacc_mean  \n",
       "0      0.7929  \n",
       "1      0.6492  \n",
       "2      0.7108  \n",
       "3      0.8074  \n",
       "4      0.7055  \n",
       "5      0.7708  \n",
       "6      0.7359  \n",
       "7      0.7449  \n",
       "8      0.7917  \n",
       "9      0.7901  \n",
       "10     0.7781  \n",
       "11     0.7781  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# BoW: no scaler (keep sparse)\n",
    "for name, clf in models_bow.items():\n",
    "    pipe = Pipeline([(\"clf\", clf)])\n",
    "    results.append(evaluate_model(f\"{name} + BoW\", pipe, X_bow, y))\n",
    "\n",
    "# Embeddings: scale first (dense)\n",
    "for name, clf in models_dense.items():\n",
    "    pipe_unw = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", clf)])\n",
    "    pipe_w   = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", clf)])\n",
    "    results.append(evaluate_model(f\"{name} + Emb-Unweighted\", pipe_unw, X_unw, y))\n",
    "    results.append(evaluate_model(f\"{name} + Emb-WeightedTFIDF\", pipe_w,   X_w,   y))\n",
    "\n",
    "df_all = pd.DataFrame(results)\n",
    "metric_cols = [c for c in df_all.columns if c.endswith(\"_mean\")]\n",
    "df_all_sorted = df_all.sort_values(\"f1_mean\", ascending=False).reset_index(drop=True)\n",
    "df_all_sorted[[\"Exp\"] + metric_cols].round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extended comparison highlights some interesting patterns:  \n",
    "\n",
    "- **Best overall**: **Multinomial Naive Bayes with BoW** achieves the top scores, with the highest **F1 (0.923)** and **ROC-AUC (0.900)**, making it the standout performer.  \n",
    "- **Close runner-up**: **Random Forest with BoW** also performs strongly (**F1 = 0.919**, **ROC-AUC = 0.891**), though its **Balanced Accuracy (0.649)** is much lower, indicating it struggles more with the minority class.  \n",
    "- **Neural models**: The **MLP with embeddings** performs better than Logistic Regression and SVM on dense inputs (**F1 ~0.906 unweighted, 0.903 weighted**), suggesting non-linear models can leverage embeddings more effectively.  \n",
    "- **Linear models**: Logistic Regression and Linear SVM again confirm that **BoW works best for them**, while embedding-based inputs lag behind.  \n",
    "- **Histogram Gradient Boosting** achieves reasonable results with embeddings (**F1 ~0.882**) but does not surpass the top BoW-based models.  \n",
    "\n",
    "**Conclusion:** For this dataset, **BoW-based models clearly outperform embedding-based ones**, with **Naive Bayes** and **Random Forest** showing especially strong results. Among embeddings, **MLP** provides the best use of dense representations, though still below BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dig deeper into imbalance handling, we directly compare **Logistic Regression with balanced class weights** against **Logistic Regression with SMOTE oversampling** on the unweighted embeddings.  \n",
    "\n",
    "We evaluate both under the same 5-fold CV setup and compute the **difference (Δ)** in performance metrics (SMOTE − Balanced).  \n",
    "This makes it easy to see whether oversampling provides any clear advantage over class weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>Balanced_mean</th>\n",
       "      <th>Balanced_std</th>\n",
       "      <th>SMOTE_mean</th>\n",
       "      <th>SMOTE_std</th>\n",
       "      <th>Δ_acc</th>\n",
       "      <th>Δ_f1</th>\n",
       "      <th>Δ_roc_auc</th>\n",
       "      <th>Δ_bacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.8018</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacc</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    metric  Balanced_mean  Balanced_std  SMOTE_mean  SMOTE_std   Δ_acc  \\\n",
       "0      acc         0.7960        0.0089      0.8018     0.0071  0.0058   \n",
       "1       f1         0.8649        0.0069      0.8698     0.0054  0.0049   \n",
       "2  roc_auc         0.8708        0.0034      0.8681     0.0041 -0.0027   \n",
       "3     bacc         0.7917        0.0082      0.7884     0.0064 -0.0033   \n",
       "\n",
       "     Δ_f1  Δ_roc_auc  Δ_bacc  \n",
       "0  0.0058     0.0058  0.0058  \n",
       "1  0.0049     0.0049  0.0049  \n",
       "2 -0.0027    -0.0027 -0.0027  \n",
       "3 -0.0033    -0.0033 -0.0033  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_bal = LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE)\n",
    "pipe_bal_unw = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", logreg_bal)])\n",
    "\n",
    "logreg_plain = LogisticRegression(max_iter=2000, class_weight=None, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "pipe_smote_unw = ImbPipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "    (\"clf\", logreg_plain),\n",
    "])\n",
    "\n",
    "res_bal = cross_validate(pipe_bal_unw, X_unw, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "res_smt = cross_validate(pipe_smote_unw, X_unw, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "comp = pd.DataFrame({\n",
    "    \"metric\": list(scoring.keys()),\n",
    "    \"Balanced_mean\": [res_bal[f\"test_{m}\"].mean() for m in scoring],\n",
    "    \"Balanced_std\":  [res_bal[f\"test_{m}\"].std()  for m in scoring],\n",
    "    \"SMOTE_mean\":    [res_smt[f\"test_{m}\"].mean() for m in scoring],\n",
    "    \"SMOTE_std\":     [res_smt[f\"test_{m}\"].std()  for m in scoring],\n",
    "}).round(4)\n",
    "\n",
    "# Add delta columns (SMOTE - Balanced)\n",
    "for m in scoring:\n",
    "    comp[f\"Δ_{m}\"] = (comp[f\"SMOTE_mean\"] - comp[f\"Balanced_mean\"]).round(4)\n",
    "\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison shows only minor differences between class weighting and SMOTE:  \n",
    "\n",
    "- **Accuracy and F1**: SMOTE gives a small boost (+0.006 in both).  \n",
    "- **ROC-AUC and Balanced Accuracy**: slightly lower with SMOTE (−0.003).  \n",
    "\n",
    "Overall, the two strategies perform almost identically.  \n",
    "Class weighting is already effective, and SMOTE does not provide a clear advantage — the small gains in accuracy/F1 are offset by small drops in ROC-AUC and balanced accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the same comparison — **Logistic Regression with balanced class weights** vs **Logistic Regression with SMOTE** — but this time using the **TF-IDF Weighted FastText embeddings**.  \n",
    "\n",
    "The setup is identical to the unweighted case, and we again calculate the **Δ (SMOTE − Balanced)** for each metric to see if oversampling provides any consistent benefit with this feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>Balanced_mean</th>\n",
       "      <th>Balanced_std</th>\n",
       "      <th>SMOTE_mean</th>\n",
       "      <th>SMOTE_std</th>\n",
       "      <th>Δ_acc</th>\n",
       "      <th>Δ_f1</th>\n",
       "      <th>Δ_roc_auc</th>\n",
       "      <th>Δ_bacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>-0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacc</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    metric  Balanced_mean  Balanced_std  SMOTE_mean  SMOTE_std   Δ_acc  \\\n",
       "0      acc         0.7843        0.0101      0.7941     0.0105  0.0098   \n",
       "1       f1         0.8566        0.0077      0.8645     0.0081  0.0079   \n",
       "2  roc_auc         0.8601        0.0042      0.8572     0.0044 -0.0029   \n",
       "3     bacc         0.7781        0.0085      0.7779     0.0067 -0.0002   \n",
       "\n",
       "     Δ_f1  Δ_roc_auc  Δ_bacc  \n",
       "0  0.0098     0.0098  0.0098  \n",
       "1  0.0079     0.0079  0.0079  \n",
       "2 -0.0029    -0.0029 -0.0029  \n",
       "3 -0.0002    -0.0002 -0.0002  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_bal_w = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", logreg_bal)])\n",
    "pipe_smote_w = ImbPipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "    (\"clf\", logreg_plain),\n",
    "])\n",
    "\n",
    "res_bal_w = cross_validate(pipe_bal_w, X_w, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "res_smt_w = cross_validate(pipe_smote_w, X_w, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "comp_w = pd.DataFrame({\n",
    "    \"metric\": list(scoring.keys()),\n",
    "    \"Balanced_mean\": [res_bal_w[f\"test_{m}\"].mean() for m in scoring],\n",
    "    \"Balanced_std\":  [res_bal_w[f\"test_{m}\"].std()  for m in scoring],\n",
    "    \"SMOTE_mean\":    [res_smt_w[f\"test_{m}\"].mean() for m in scoring],\n",
    "    \"SMOTE_std\":     [res_smt_w[f\"test_{m}\"].std()  for m in scoring],\n",
    "}).round(4)\n",
    "\n",
    "for m in scoring:\n",
    "    comp_w[f\"Δ_{m}\"] = (comp_w[f\"SMOTE_mean\"] - comp_w[f\"Balanced_mean\"]).round(4)\n",
    "\n",
    "comp_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **TF-IDF Weighted embeddings**, the results mirror the unweighted case:  \n",
    "\n",
    "- **Accuracy and F1**: SMOTE shows small improvements (+0.010 in accuracy, +0.008 in F1).  \n",
    "- **ROC-AUC and Balanced Accuracy**: slightly worse with SMOTE (−0.003 and −0.0002, respectively).  \n",
    "\n",
    "Overall, the differences remain marginal.  \n",
    "As with the unweighted embeddings, **class weighting alone is sufficient**, and SMOTE does not provide a consistent or meaningful advantage here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = comp.set_index(\"metric\")[[\"Δ_f1\", \"Δ_bacc\", \"Δ_roc_auc\", \"Δ_acc\"]]\n",
    "ax = plot_df.plot(kind=\"bar\", figsize=(7,4), edgecolor=\"black\")\n",
    "ax.axhline(0, linewidth=1)\n",
    "ax.set_title(\"SMOTE - Balanced (Unweighted Embeddings) — Δ by metric\")\n",
    "ax.set_ylabel(\"Δ score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar chart visualizes the effect of SMOTE compared to class weighting on unweighted embeddings.  \n",
    "\n",
    "- **Accuracy and F1**: both see slight gains with SMOTE.  \n",
    "- **ROC-AUC and Balanced Accuracy**: both decrease a little under SMOTE.  \n",
    "\n",
    "The changes are very small in all cases, reinforcing that **SMOTE does not meaningfully improve performance** over using class weights alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exp</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>bacc_mean</th>\n",
       "      <th>acc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB + BoW</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.8742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest (balanced) + BoW</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>0.6492</td>\n",
       "      <td>0.8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP (128) + Emb-Unweighted</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>0.7108</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogReg (balanced) + BoW</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.8881</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP (128) + Emb-WeightedTFIDF</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC (balanced) + BoW</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.7708</td>\n",
       "      <td>0.8357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGB (balanced) + Emb-WeightedTFIDF</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.7359</td>\n",
       "      <td>0.8121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGB (balanced) + Emb-Unweighted</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>0.8422</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogReg (balanced) + Emb-Unweighted</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.7960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearSVC (balanced) + Emb-Unweighted</td>\n",
       "      <td>0.8637</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.7943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg (balanced) + Emb-WeightedTFIDF</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.7843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearSVC (balanced) + Emb-WeightedTFIDF</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.7835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Exp  f1_mean  roc_auc_mean  \\\n",
       "0                        MultinomialNB + BoW   0.9229        0.8995   \n",
       "1              RandomForest (balanced) + BoW   0.9193        0.8906   \n",
       "2                 MLP (128) + Emb-Unweighted   0.9061        0.8378   \n",
       "3                    LogReg (balanced) + BoW   0.9048        0.8881   \n",
       "4              MLP (128) + Emb-WeightedTFIDF   0.9029        0.8303   \n",
       "5                 LinearSVC (balanced) + BoW   0.8968        0.8505   \n",
       "6      HistGB (balanced) + Emb-WeightedTFIDF   0.8817        0.8330   \n",
       "7         HistGB (balanced) + Emb-Unweighted   0.8813        0.8422   \n",
       "8         LogReg (balanced) + Emb-Unweighted   0.8649        0.8708   \n",
       "9      LinearSVC (balanced) + Emb-Unweighted   0.8637        0.8708   \n",
       "10     LogReg (balanced) + Emb-WeightedTFIDF   0.8566        0.8601   \n",
       "11  LinearSVC (balanced) + Emb-WeightedTFIDF   0.8560        0.8604   \n",
       "\n",
       "    bacc_mean  acc_mean  \n",
       "0      0.7929    0.8742  \n",
       "1      0.6492    0.8594  \n",
       "2      0.7108    0.8440  \n",
       "3      0.8074    0.8496  \n",
       "4      0.7055    0.8389  \n",
       "5      0.7708    0.8357  \n",
       "6      0.7359    0.8121  \n",
       "7      0.7449    0.8125  \n",
       "8      0.7917    0.7960  \n",
       "9      0.7901    0.7943  \n",
       "10     0.7781    0.7843  \n",
       "11     0.7781    0.7835  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard = df_all_sorted[[\"Exp\", \"f1_mean\", \"roc_auc_mean\", \"bacc_mean\", \"acc_mean\"]].round(4)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap up **Question 1**, we build a leaderboard of all models and feature representations, sorted by **F1 score**.  \n",
    "This gives a clear view of which combinations perform best across multiple metrics.  \n",
    "\n",
    "**Key takeaways from the leaderboard:**  \n",
    "- **Top performer:** Multinomial Naive Bayes with BoW (**F1 = 0.923, ROC-AUC = 0.900**).  \n",
    "- **Close second:** Random Forest with BoW (**F1 = 0.919**), though its balanced accuracy (0.649) is weaker, showing less reliability on the minority class.  \n",
    "- **Strong embeddings:** MLP on unweighted embeddings (**F1 = 0.906**) and weighted embeddings (**F1 = 0.903**) outperform linear models with embeddings, but still trail BoW methods.  \n",
    "- **Linear models (LogReg, SVM):** Consistently favor BoW, achieving solid but not top results.  \n",
    "- **Histogram Gradient Boosting:** Reasonable with embeddings (**F1 ~0.88**), but again below the BoW-based models.  \n",
    "\n",
    "**Conclusion for Q1:**  \n",
    "Bag-of-Words is the most effective representation for this dataset, especially with simpler models like Naive Bayes and Random Forest.  \n",
    "While embeddings paired with MLP show promise, they do not surpass BoW approaches.  \n",
    "For handling class imbalance, **balanced class weights are sufficient**, with SMOTE offering no clear advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Summary  \n",
    "\n",
    "In **Question 1**, we compared different feature representations and models to see which setup performs best for classifying clothing reviews.  \n",
    "\n",
    "- **BoW representations** consistently outperformed embeddings, with **Multinomial Naive Bayes (F1 = 0.923)** and **Random Forest (F1 = 0.919)** leading the results.  \n",
    "- **Logistic Regression and SVM** also favored BoW, achieving solid F1 scores (~0.90) but not surpassing Naive Bayes.  \n",
    "- **Embedding-based models** worked better with non-linear classifiers like MLP, reaching F1 ≈ 0.906, though still below BoW methods.  \n",
    "- **Imbalance handling:** Using `class_weight=\"balanced\"` was already effective, while SMOTE offered only marginal changes and no consistent improvements.  \n",
    "\n",
    "**Overall:** The simplest representation (BoW) with lightweight models (Naive Bayes, Random Forest) provided the strongest and most reliable performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Question 2 — Does more information help?\n",
    "\n",
    "In Task 2, we focused only on the **review text** when generating feature representations.  \n",
    "Now, we expand our investigation to see whether adding the **review title** improves classification performance.  \n",
    "\n",
    "We compare three input settings:  \n",
    "- **Title only**  \n",
    "- **Text only** (baseline from Q1)  \n",
    "- **Title + Text** (concatenated into a single document)  \n",
    "\n",
    "Each input is tested across the same feature types (BoW, Unweighted embeddings, TF-IDF Weighted embeddings) and models, using the same evaluation setup as in Q1.  \n",
    "This allows us to directly measure the contribution of Title information to model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Baseline Models Experiement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first prepare the inputs for Q2.  \n",
    "If `Title` exists, we clean it and **tokenize with the same regex** from Task 1 to stay consistent.  \n",
    "We then build three text variants:\n",
    "\n",
    "- **Title only** (`titles_clean`)  \n",
    "- **Text only** (`texts_clean`, from Task 1 tokens)  \n",
    "- **Title + Text** (`combo_clean`, concatenated and re-spaced)\n",
    "\n",
    "A quick print verifies that the strings look correct before vectorizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse: df (processed.csv loaded), vocab, tokenizer/tokenize(), ft_model, idf_weights, cv, scoring, y\n",
    "assert 'Recommended IND' in df.columns, \"Target column not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "TITLE -> some major design flaws\n",
      "TEXT  -> ['high', 'hope', 'wanted', 'work', 'initially', 'petite', 'usual', 'found', 'outrageously', 'fact', \n",
      "COMBO -> some major design flaws ['high', 'hope', 'wanted', 'work', 'initially', 'petite', 'usual', 'found', \n"
     ]
    }
   ],
   "source": [
    "# Use Title if available; otherwise fill with blanks (so code still runs)\n",
    "if 'Title' in df.columns:\n",
    "    titles_raw = df['Title'].fillna('').astype(str)\n",
    "else:\n",
    "    print(\"WARNING: 'Title' column not found in df; Title-only/Title+Text will be blank.\")\n",
    "    titles_raw = pd.Series([''] * len(df), index=df.index)\n",
    "\n",
    "# Text corpus from your processed tokens (already cleaned in Task 1)\n",
    "texts_clean = df['processed_tokens'].fillna('').astype(str)\n",
    "\n",
    "# Tokenize title with the same regex rule to keep consistency\n",
    "titles_clean = titles_raw.apply(lambda s: \" \".join(tokenize(s)))\n",
    "\n",
    "# Concatenate Title + Text (already space-separated tokens)\n",
    "combo_clean = (titles_clean.str.cat(texts_clean, sep=\" \").str.replace(r\"\\s+\", \" \", regex=True).str.strip())\n",
    "\n",
    "# Quick sanity\n",
    "print(\"Examples:\\nTITLE ->\", titles_clean.iloc[0][:100])\n",
    "print(\"TEXT  ->\", texts_clean.iloc[0][:100])\n",
    "print(\"COMBO ->\", combo_clean.iloc[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build feature matrices for the three **input variants** (Title, Text, Title+Text) across all **representation types**:\n",
    "\n",
    "- **BoW (Count)**: reuse the fixed vocabulary from Task 1 to keep indices consistent.  \n",
    "- **Unweighted embeddings**: mean of FastText vectors per document.  \n",
    "- **TF-IDF weighted embeddings**: FastText vectors scaled by IDF learned from **Review Text** (same weights as in Task 2).\n",
    "\n",
    "We then print the shapes to confirm that Title, Text, and Title+Text versions align with each other and with `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes | BoW: (19652, 6548) (19652, 6548) (19652, 6548) | Unw: (19652, 300) (19652, 300) (19652, 300) | W: (19652, 300) (19652, 300) (19652, 300)\n"
     ]
    }
   ],
   "source": [
    "# --- BoW (reuse the same vocabulary from Task 1, as required) ---\n",
    "cv_bow = CountVectorizer(vocabulary=vocab)\n",
    "X_title_bow = cv_bow.transform(titles_clean)\n",
    "# You already have X_bow for Text-only; if not, uncomment:\n",
    "# X_text_bow  = cv_bow.transform(texts_clean)\n",
    "X_combo_bow = cv_bow.transform(combo_clean)\n",
    "\n",
    "# --- Unweighted embeddings (mean of word vectors) ---\n",
    "def doc_avg_embedding(doc_str):\n",
    "    toks = tokenize(doc_str)\n",
    "    vecs = [ft_model[t] for t in toks if t in ft_model]\n",
    "    if not vecs:\n",
    "        return np.zeros(ft_model.vector_size, dtype=np.float32)\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "X_title_unw = np.vstack([doc_avg_embedding(s) for s in titles_clean])\n",
    "# You already have X_unw for Text-only\n",
    "X_combo_unw = np.vstack([doc_avg_embedding(s) for s in combo_clean])\n",
    "\n",
    "# --- TF-IDF weighted embeddings (uses IDF learned from Review Text) ---\n",
    "def doc_tfidf_weighted_embedding(doc_str):\n",
    "    toks = tokenize(doc_str)\n",
    "    vec_sum, w_sum = None, 0.0\n",
    "    for t in toks:\n",
    "        if (t in ft_model) and (t in idf_weights):  # keep only tokens known to IDF from Review Text\n",
    "            w = float(idf_weights[t])\n",
    "            v = ft_model[t] * w\n",
    "            vec_sum = v if vec_sum is None else (vec_sum + v)\n",
    "            w_sum += w\n",
    "    if (vec_sum is None) or (w_sum == 0.0):\n",
    "        return np.zeros(ft_model.vector_size, dtype=np.float32)\n",
    "    return (vec_sum / w_sum)\n",
    "\n",
    "X_title_w = np.vstack([doc_tfidf_weighted_embedding(s) for s in titles_clean])\n",
    "# You already have X_w for Text-only\n",
    "X_combo_w = np.vstack([doc_tfidf_weighted_embedding(s) for s in combo_clean])\n",
    "\n",
    "print(\"Shapes | BoW:\", X_title_bow.shape, X_bow.shape, X_combo_bow.shape,\n",
    "      \"| Unw:\", X_title_unw.shape, X_unw.shape, X_combo_unw.shape,\n",
    "      \"| W:\", X_title_w.shape, X_w.shape, X_combo_w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin our Q2 experiments with a **Logistic Regression** model using `class_weight=\"balanced\"`.  \n",
    "This ensures that minority and majority classes are treated fairly during training.  \n",
    "\n",
    "As before:  \n",
    "- **BoW (Count vectors)** is used directly without scaling.  \n",
    "- **Unweighted embeddings** are scaled before classification.  \n",
    "- **TF-IDF Weighted embeddings** are also scaled.  \n",
    "\n",
    "These pipelines set up a consistent baseline to evaluate the impact of adding **Title** information in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_bal = LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1, random_state=42)\n",
    "\n",
    "pipe_bow = Pipeline([(\"clf\", logreg_bal)])  # no scaler for sparse BoW\n",
    "pipe_unw = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", logreg_bal)])\n",
    "pipe_w   = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", logreg_bal)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate **Logistic Regression (balanced)** across all three input settings:  \n",
    "- **Title only**  \n",
    "- **Text only**  \n",
    "- **Title + Text**  \n",
    "\n",
    "For each input, we test the three representation types (BoW, Unweighted embeddings, TF-IDF Weighted embeddings).  \n",
    "We use a helper function `cv_means` to run 5-fold CV and return the mean scores for all metrics.  \n",
    "\n",
    "The results are collected into a dataframe, rounded for readability, and sorted within each representation by **F1 score**.  \n",
    "This allows us to directly compare the effect of adding Title information to the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rep</th>\n",
       "      <th>Input</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>mean_roc_auc</th>\n",
       "      <th>mean_bacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.9223</td>\n",
       "      <td>0.8439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Text</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.8881</td>\n",
       "      <td>0.8074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.8190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.8420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title</td>\n",
       "      <td>0.8314</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.8393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Text</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.7917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.8212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Title</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>0.8072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Text</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Rep       Input  mean_acc  mean_f1  mean_roc_auc  mean_bacc\n",
       "0         BoW  Title+Text    0.8794   0.9243        0.9223     0.8439\n",
       "1         BoW        Text    0.8496   0.9048        0.8881     0.8074\n",
       "2         BoW       Title    0.8250   0.8857        0.8952     0.8190\n",
       "3  Unweighted  Title+Text    0.8442   0.8987        0.9193     0.8420\n",
       "4  Unweighted       Title    0.8314   0.8892        0.9078     0.8393\n",
       "5  Unweighted        Text    0.7960   0.8649        0.8708     0.7917\n",
       "6    Weighted  Title+Text    0.8247   0.8852        0.9026     0.8212\n",
       "7    Weighted       Title    0.8048   0.8707        0.8752     0.8072\n",
       "8    Weighted        Text    0.7843   0.8566        0.8601     0.7781"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cv_means(pipe, X, y):\n",
    "    res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "    return {f\"mean_{m}\": float(np.mean(res[f\"test_{m}\"])) for m in scoring}\n",
    "\n",
    "rows = []\n",
    "# BoW\n",
    "rows.append({\"Rep\":\"BoW\", \"Input\":\"Title\",      **cv_means(pipe_bow, X_title_bow, y)})\n",
    "rows.append({\"Rep\":\"BoW\", \"Input\":\"Text\",       **cv_means(pipe_bow, X_bow,       y)})\n",
    "rows.append({\"Rep\":\"BoW\", \"Input\":\"Title+Text\", **cv_means(pipe_bow, X_combo_bow, y)})\n",
    "\n",
    "# Unweighted\n",
    "rows.append({\"Rep\":\"Unweighted\", \"Input\":\"Title\",      **cv_means(pipe_unw, X_title_unw, y)})\n",
    "rows.append({\"Rep\":\"Unweighted\", \"Input\":\"Text\",       **cv_means(pipe_unw, X_unw,       y)})\n",
    "rows.append({\"Rep\":\"Unweighted\", \"Input\":\"Title+Text\", **cv_means(pipe_unw, X_combo_unw, y)})\n",
    "\n",
    "# Weighted\n",
    "rows.append({\"Rep\":\"Weighted\", \"Input\":\"Title\",      **cv_means(pipe_w, X_title_w, y)})\n",
    "rows.append({\"Rep\":\"Weighted\", \"Input\":\"Text\",       **cv_means(pipe_w, X_w,       y)})\n",
    "rows.append({\"Rep\":\"Weighted\", \"Input\":\"Title+Text\", **cv_means(pipe_w, X_combo_w, y)})\n",
    "\n",
    "q2_results = pd.DataFrame(rows)\n",
    "for c in [c for c in q2_results.columns if c.startswith(\"mean_\")]:\n",
    "    q2_results[c] = q2_results[c].round(4)\n",
    "\n",
    "q2_results = q2_results.sort_values([\"Rep\",\"mean_f1\"], ascending=[True, False]).reset_index(drop=True)\n",
    "q2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that adding the **Title** information consistently improves performance across all representations:  \n",
    "\n",
    "- **BoW**:  \n",
    "  - **Title+Text** gives the best overall performance (**F1 = 0.924**, **ROC-AUC = 0.922**), a clear gain over **Text only (F1 = 0.905)**.  \n",
    "  - **Title only** performs weaker than Text, but still provides reasonable scores (F1 = 0.886).  \n",
    "\n",
    "- **Unweighted embeddings**:  \n",
    "  - **Title+Text** also improves results (**F1 = 0.899**) compared to Text only (**F1 = 0.865**).  \n",
    "  - Title alone performs slightly below Title+Text but still better than Text alone.  \n",
    "\n",
    "- **TF-IDF Weighted embeddings**:  \n",
    "  - The same pattern holds, with **Title+Text** (F1 = 0.885) outperforming Text only (**F1 = 0.857**).  \n",
    "  - Title alone (F1 = 0.871) again shows better results than Text only.  \n",
    "\n",
    "**Conclusion:** Incorporating **Title information** boosts classification performance in all cases, with the strongest gains seen in the **BoW model**. Title by itself is not as strong as Text, but when combined, it clearly enhances accuracy and F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the impact of **Title** more explicit, we calculate the **delta (Δ)** of each metric relative to the **Text-only baseline**.  \n",
    "\n",
    "For each representation (BoW, Unweighted, Weighted):  \n",
    "- We take the performance of **Text only** as the baseline.  \n",
    "- We compute the difference (Δ) for **Title** and **Title+Text** across all metrics (F1, Balanced Accuracy, ROC-AUC, Accuracy).  \n",
    "\n",
    "This highlights how much value Title information adds, either on its own or when combined with Text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rep</th>\n",
       "      <th>Input</th>\n",
       "      <th>Δ_f1</th>\n",
       "      <th>Δ_bacc</th>\n",
       "      <th>Δ_roc_auc</th>\n",
       "      <th>Δ_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Text</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title</td>\n",
       "      <td>-0.0191</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>-0.0246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Text</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Title</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Text</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Rep       Input    Δ_f1  Δ_bacc  Δ_roc_auc   Δ_acc\n",
       "0         BoW  Title+Text  0.0195  0.0365     0.0342  0.0298\n",
       "1         BoW        Text  0.0000  0.0000     0.0000  0.0000\n",
       "2         BoW       Title -0.0191  0.0116     0.0071 -0.0246\n",
       "3  Unweighted  Title+Text  0.0338  0.0503     0.0485  0.0482\n",
       "4  Unweighted       Title  0.0243  0.0476     0.0370  0.0354\n",
       "5  Unweighted        Text  0.0000  0.0000     0.0000  0.0000\n",
       "6    Weighted  Title+Text  0.0286  0.0431     0.0425  0.0404\n",
       "7    Weighted       Title  0.0141  0.0291     0.0151  0.0205\n",
       "8    Weighted        Text  0.0000  0.0000     0.0000  0.0000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def deltas_vs_text(df):\n",
    "    out = []\n",
    "    for rep, grp in df.groupby(\"Rep\"):\n",
    "        # find the Text-only row as baseline\n",
    "        base = grp.loc[grp[\"Input\"]==\"Text\"].iloc[0]\n",
    "        for _, row in grp.iterrows():\n",
    "            d = {\"Rep\": rep, \"Input\": row[\"Input\"]}\n",
    "            for m in [\"mean_f1\",\"mean_bacc\",\"mean_roc_auc\",\"mean_acc\"]:\n",
    "                if m in row and m in base:\n",
    "                    d[f\"Δ_{m.replace('mean_','')}\"] = (row[m] - base[m]).round(4)\n",
    "            out.append(d)\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "q2_delta = deltas_vs_text(q2_results)\n",
    "q2_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Δ table shows the performance change relative to **Text only**:  \n",
    "\n",
    "- **BoW**:  \n",
    "  - Adding Title to Text gives a modest boost (**+0.020 F1, +0.036 Balanced Accuracy, +0.034 ROC-AUC**).  \n",
    "  - Title alone underperforms Text (**−0.019 F1**), confirming it’s not as informative by itself.  \n",
    "\n",
    "- **Unweighted embeddings**:  \n",
    "  - Title+Text provides the largest gains (**+0.034 F1, +0.050 Balanced Accuracy, +0.049 ROC-AUC**).  \n",
    "  - Even Title alone improves results over Text-only (**+0.024 F1**).  \n",
    "\n",
    "- **TF-IDF Weighted embeddings**:  \n",
    "  - Similar trend: Title+Text outperforms Text-only (**+0.029 F1, +0.043 Balanced Accuracy, +0.043 ROC-AUC**).  \n",
    "  - Title alone offers smaller but still positive improvements (**+0.014 F1**).  \n",
    "\n",
    "**Summary:** Adding the Title consistently improves classification across all representations, with the strongest relative boost in **Unweighted embeddings**, followed by Weighted embeddings and BoW. Title on its own is weaker than Text, but still better than nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = q2_delta[q2_delta[\"Input\"]!=\"Text\"].pivot(index=\"Rep\", columns=\"Input\", values=\"Δ_f1\")\n",
    "ax = plot_df.plot(kind=\"bar\", figsize=(6.0,4.0), edgecolor=\"black\")\n",
    "ax.axhline(0, linewidth=1)\n",
    "ax.set_ylabel(\"Δ F1 vs Text-only\")\n",
    "ax.set_title(\"Q2 — Effect of adding Title\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot clearly shows how adding **Title** affects F1 compared to using **Text only**:  \n",
    "\n",
    "- **BoW**: Title alone hurts performance (negative ΔF1), but Title+Text gives a small boost.  \n",
    "- **Unweighted embeddings**: Adding Title produces the strongest improvements, especially when combined with Text (**ΔF1 ≈ +0.034**).  \n",
    "- **Weighted embeddings**: Both Title and Title+Text help, with Title+Text again giving the larger gain.  \n",
    "\n",
    "**Takeaway:** Title information is most valuable when combined with Text, consistently raising F1 across all representations — with the largest benefit seen in the **Unweighted embeddings**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Additional Models Experiement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure reproducibility, we **rebuild** all three input variants (Title, Text, Title+Text) and regenerate their feature matrices from scratch:\n",
    "\n",
    "1) **Inputs** — clean/tokenize `Title`, keep `Text` from Task 1, and concatenate for `Title+Text`.  \n",
    "2) **BoW** — vectorize with the **fixed Task 1 vocabulary** (keeps indices consistent).  \n",
    "3) **Unweighted embeddings** — FastText mean per document.  \n",
    "4) **TF-IDF weighted embeddings** — FastText vectors scaled by IDF learned from **Review Text**.\n",
    "\n",
    "We then print shapes for (Title, Text, Title+Text) under each representation to confirm alignment before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs (recreate safely)\n",
    "titles_raw = df['Title'].fillna('').astype(str) if 'Title' in df.columns else pd.Series(['']*len(df), index=df.index)\n",
    "texts_clean = df['processed_tokens'].fillna('').astype(str)  # from Task 1\n",
    "titles_clean = titles_raw.apply(lambda s: \" \".join(tokenize(s)))\n",
    "combo_clean = (titles_clean.str.cat(texts_clean, sep=\" \")\n",
    "               .str.replace(r\"\\s+\", \" \", regex=True).str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW (fixed vocab from Task 1)\n",
    "cv_bow = CountVectorizer(vocabulary=vocab)\n",
    "X_title_bow = cv_bow.transform(titles_clean)\n",
    "X_text_bow  = cv_bow.transform(texts_clean)   # (alias of your X_bow, rebuilt for completeness)\n",
    "X_combo_bow = cv_bow.transform(combo_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted embeddings\n",
    "def doc_avg_embedding(doc_str):\n",
    "    toks = tokenize(doc_str)\n",
    "    vecs = [ft_model[t] for t in toks if t in ft_model]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(ft_model.vector_size, dtype=np.float32)\n",
    "\n",
    "X_title_unw = np.vstack([doc_avg_embedding(s) for s in titles_clean])\n",
    "X_text_unw  = np.vstack([doc_avg_embedding(s) for s in texts_clean])    # (alias of X_unw)\n",
    "X_combo_unw = np.vstack([doc_avg_embedding(s) for s in combo_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF weighted embeddings (reuse idf_weights from Text)\n",
    "def doc_tfidf_weighted_embedding(doc_str):\n",
    "    toks = tokenize(doc_str); wsum = 0.0; acc = None\n",
    "    for t in toks:\n",
    "        if (t in ft_model) and (t in idf_weights):\n",
    "            w = float(idf_weights[t]); v = ft_model[t] * w\n",
    "            acc = v if acc is None else (acc + v); wsum += w\n",
    "    return (acc / wsum) if (acc is not None and wsum>0) else np.zeros(ft_model.vector_size, dtype=np.float32)\n",
    "\n",
    "X_title_w = np.vstack([doc_tfidf_weighted_embedding(s) for s in titles_clean])\n",
    "X_text_w  = np.vstack([doc_tfidf_weighted_embedding(s) for s in texts_clean])   # (alias of X_w)\n",
    "X_combo_w = np.vstack([doc_tfidf_weighted_embedding(s) for s in combo_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW   : (19652, 6548) (19652, 6548) (19652, 6548)\n",
      "Unw   : (19652, 300) (19652, 300) (19652, 300)\n",
      "TF-IDF: (19652, 300) (19652, 300) (19652, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"BoW   :\", X_title_bow.shape, X_text_bow.shape, X_combo_bow.shape)\n",
    "print(\"Unw   :\", X_title_unw.shape,  X_text_unw.shape,  X_combo_unw.shape)\n",
    "print(\"TF-IDF:\", X_title_w.shape,    X_text_w.shape,    X_combo_w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the set of models to be tested in **Question 2**.  \n",
    "As in Q1, we separate them into two groups depending on the representation type:  \n",
    "\n",
    "- **Sparse-friendly (BoW)**:  \n",
    "  - Logistic Regression (balanced)  \n",
    "  - Linear SVM (balanced)  \n",
    "  - Multinomial Naive Bayes  \n",
    "  - Random Forest (balanced)  \n",
    "\n",
    "- **Dense-friendly (Embeddings)**:  \n",
    "  - Logistic Regression (balanced)  \n",
    "  - Linear SVM (balanced)  \n",
    "  - Histogram-based Gradient Boosting (balanced)  \n",
    "  - Multi-Layer Perceptron (MLP, 128 hidden units)  \n",
    "\n",
    "This mix covers both linear and non-linear models, ensuring a fair comparison of BoW vs embedding representations with Title, Text, and Title+Text inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# Sparse-friendly (BoW)\n",
    "models_bow = {\n",
    "    \"LogReg (balanced)\": LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    \"LinearSVC (balanced)\": LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"RandomForest (balanced)\": RandomForestClassifier(\n",
    "        n_estimators=250, class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Dense-friendly (Embeddings)\n",
    "models_dense = {\n",
    "    \"LogReg (balanced)\": LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    \"LinearSVC (balanced)\": LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "    \"HistGB (balanced)\": HistGradientBoostingClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\"),\n",
    "    \"MLP (128)\": MLPClassifier(hidden_layer_sizes=(128,), max_iter=80, random_state=RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate multiple models efficiently, we define a helper function `evaluate_pipeline`.  \n",
    "It runs **cross-validation** on a given pipeline, collects all metric scores, and returns a summary row:  \n",
    "\n",
    "- Includes the experiment name (`RepInputModel`)  \n",
    "- Stores the **mean** and **standard deviation** for each metric (Accuracy, F1, ROC-AUC, Balanced Accuracy)  \n",
    "\n",
    "This structure makes it easier to aggregate results across different representations, inputs, and models in a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline(exp_name, pipe, X, y, cv=cv, scoring=scoring):\n",
    "    res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "    row = {\"RepInputModel\": exp_name}\n",
    "    for m in scoring:\n",
    "        row[f\"{m}_mean\"] = float(np.mean(res[f\"test_{m}\"]))\n",
    "        row[f\"{m}_std\"]  = float(np.std(res[f\"test_{m}\"]))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run **all models** across every **representation** (BoW, Unweighted, Weighted) and **input** (Title, Text, Title+Text).\n",
    "\n",
    "- `run_block(...)` builds a pipeline per model, scaling only for dense embeddings.\n",
    "- Each experiment is evaluated with 5-fold CV via `evaluate_pipeline`, and the results are appended to a list.\n",
    "- We then unpack the composite experiment name into **Rep / Input / Model** and build a **leaderboard** sorted by **F1** (primary metric under imbalance), with **ROC-AUC** as a tiebreaker.\n",
    "\n",
    "The table below shows the top results (rounded) for quick comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse the **model definitions** from Q1 and apply them to Q2.  \n",
    "The models are grouped by representation type:  \n",
    "\n",
    "- **Sparse-friendly (BoW):**  \n",
    "  Logistic Regression (balanced), Linear SVM (balanced), Multinomial Naive Bayes, Random Forest (balanced).  \n",
    "\n",
    "- **Dense-friendly (Embeddings):**  \n",
    "  Logistic Regression (balanced), Linear SVM (balanced), Histogram Gradient Boosting (balanced), and MLP (128 hidden units).  \n",
    "\n",
    "This ensures consistency in comparing performance across **Title**, **Text**, and **Title+Text** inputs for each representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rep</th>\n",
       "      <th>Input</th>\n",
       "      <th>Model</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>bacc_mean</th>\n",
       "      <th>acc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>0.8406</td>\n",
       "      <td>0.8887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>RandomForest (balanced)</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>0.8758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title</td>\n",
       "      <td>MLP (128)</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>0.8788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>MLP (128)</td>\n",
       "      <td>0.9258</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.7757</td>\n",
       "      <td>0.8774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>LogReg (balanced)</td>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.9223</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Text</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.8742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.9221</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.8666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>MLP (128)</td>\n",
       "      <td>0.9197</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>0.8670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Text</td>\n",
       "      <td>RandomForest (balanced)</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>0.6492</td>\n",
       "      <td>0.8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Title</td>\n",
       "      <td>MLP (128)</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.7441</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>LinearSVC (balanced)</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>0.8007</td>\n",
       "      <td>0.8632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Text</td>\n",
       "      <td>MLP (128)</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>0.7108</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title</td>\n",
       "      <td>HistGB (balanced)</td>\n",
       "      <td>0.9054</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.8266</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Text</td>\n",
       "      <td>LogReg (balanced)</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.8881</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>HistGB (balanced)</td>\n",
       "      <td>0.9041</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.7905</td>\n",
       "      <td>0.8474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Text</td>\n",
       "      <td>MLP (128)</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>HistGB (balanced)</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.8422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>LogReg (balanced)</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.8442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>LinearSVC (balanced)</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BoW</td>\n",
       "      <td>Title</td>\n",
       "      <td>RandomForest (balanced)</td>\n",
       "      <td>0.8969</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.8359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rep       Input                    Model  f1_mean  roc_auc_mean  \\\n",
       "0          BoW  Title+Text            MultinomialNB   0.9309        0.9306   \n",
       "1          BoW  Title+Text  RandomForest (balanced)   0.9280        0.9247   \n",
       "2   Unweighted       Title                MLP (128)   0.9267        0.9043   \n",
       "3   Unweighted  Title+Text                MLP (128)   0.9258        0.9030   \n",
       "4          BoW  Title+Text        LogReg (balanced)   0.9243        0.9223   \n",
       "5          BoW        Text            MultinomialNB   0.9229        0.8995   \n",
       "6          BoW       Title            MultinomialNB   0.9221        0.8889   \n",
       "7     Weighted  Title+Text                MLP (128)   0.9197        0.8841   \n",
       "8          BoW        Text  RandomForest (balanced)   0.9193        0.8906   \n",
       "9     Weighted       Title                MLP (128)   0.9191        0.8652   \n",
       "10         BoW  Title+Text     LinearSVC (balanced)   0.9149        0.8887   \n",
       "11  Unweighted        Text                MLP (128)   0.9061        0.8378   \n",
       "12  Unweighted       Title        HistGB (balanced)   0.9054        0.9153   \n",
       "13         BoW        Text        LogReg (balanced)   0.9048        0.8881   \n",
       "14  Unweighted  Title+Text        HistGB (balanced)   0.9041        0.8939   \n",
       "15    Weighted        Text                MLP (128)   0.9029        0.8303   \n",
       "16    Weighted  Title+Text        HistGB (balanced)   0.9007        0.8833   \n",
       "17  Unweighted  Title+Text        LogReg (balanced)   0.8987        0.9193   \n",
       "18  Unweighted  Title+Text     LinearSVC (balanced)   0.8986        0.9192   \n",
       "19         BoW       Title  RandomForest (balanced)   0.8969        0.8707   \n",
       "\n",
       "    bacc_mean  acc_mean  \n",
       "0      0.8406    0.8887  \n",
       "1      0.6974    0.8758  \n",
       "2      0.7777    0.8788  \n",
       "3      0.7757    0.8774  \n",
       "4      0.8439    0.8794  \n",
       "5      0.7929    0.8742  \n",
       "6      0.6931    0.8666  \n",
       "7      0.7546    0.8670  \n",
       "8      0.6492    0.8594  \n",
       "9      0.7441    0.8655  \n",
       "10     0.8007    0.8632  \n",
       "11     0.7108    0.8440  \n",
       "12     0.8266    0.8519  \n",
       "13     0.8074    0.8496  \n",
       "14     0.7905    0.8474  \n",
       "15     0.7055    0.8389  \n",
       "16     0.7845    0.8422  \n",
       "17     0.8420    0.8442  \n",
       "18     0.8429    0.8440  \n",
       "19     0.7715    0.8359  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Helper to push rows\n",
    "def run_block(rep, input_name, Xmat, model_dict, needs_scaler=False):\n",
    "    for mname, clf in model_dict.items():\n",
    "        if needs_scaler:\n",
    "            pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", clf)])\n",
    "        else:\n",
    "            pipe = Pipeline([(\"clf\", clf)])\n",
    "        tag = f\"{rep} | {input_name} | {mname}\"\n",
    "        results.append(evaluate_pipeline(tag, pipe, Xmat, y))\n",
    "\n",
    "# BoW (no scaler)\n",
    "run_block(\"BoW\", \"Title\",      X_title_bow, models_bow, needs_scaler=False)\n",
    "run_block(\"BoW\", \"Text\",       X_text_bow,  models_bow, needs_scaler=False)\n",
    "run_block(\"BoW\", \"Title+Text\", X_combo_bow, models_bow, needs_scaler=False)\n",
    "\n",
    "# Unweighted (scale)\n",
    "run_block(\"Unweighted\", \"Title\",      X_title_unw, models_dense, needs_scaler=True)\n",
    "run_block(\"Unweighted\", \"Text\",       X_text_unw,  models_dense, needs_scaler=True)\n",
    "run_block(\"Unweighted\", \"Title+Text\", X_combo_unw, models_dense, needs_scaler=True)\n",
    "\n",
    "# Weighted (scale)\n",
    "run_block(\"Weighted\", \"Title\",      X_title_w, models_dense, needs_scaler=True)\n",
    "run_block(\"Weighted\", \"Text\",       X_text_w,  models_dense, needs_scaler=True)\n",
    "run_block(\"Weighted\", \"Title+Text\", X_combo_w, models_dense, needs_scaler=True)\n",
    "\n",
    "df_q2_all = pd.DataFrame(results)\n",
    "# Split composite name for readability\n",
    "df_q2_all[[\"Rep\",\"Input\",\"Model\"]] = df_q2_all[\"RepInputModel\"].str.split(\" \\| \", expand=True)\n",
    "df_q2_all = df_q2_all.drop(columns=[\"RepInputModel\"])\n",
    "\n",
    "# Leaderboard by F1\n",
    "cols = [\"Rep\",\"Input\",\"Model\",\"f1_mean\",\"roc_auc_mean\",\"bacc_mean\",\"acc_mean\"]\n",
    "df_q2_all_leader = df_q2_all[cols].sort_values([\"f1_mean\",\"roc_auc_mean\"], ascending=False).round(4).reset_index(drop=True)\n",
    "df_q2_all_leader.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Q2 leaderboard highlights the value of **Title information** across different models and representations:  \n",
    "\n",
    "- **Top performer:**  \n",
    "  - **BoW + Title+Text with MultinomialNB** achieves the best overall scores (**F1 = 0.931, ROC-AUC = 0.931, Balanced Accuracy = 0.841**).  \n",
    "  - This shows that combining Title with Text produces a clear improvement over Text alone.  \n",
    "\n",
    "- **Other strong setups:**  \n",
    "  - **BoW + Title+Text with Random Forest** (**F1 = 0.928**) and **Logistic Regression** (**F1 = 0.924**) also perform extremely well.  \n",
    "  - **Unweighted embeddings + MLP** is the best among embedding models (**F1 ≈ 0.926 with Title, 0.926 with Title+Text**), confirming that neural models make better use of dense vectors.  \n",
    "\n",
    "- **Comparisons to Text-only baselines:**  \n",
    "  - MultinomialNB with **Text only** scored F1 = 0.923, while adding Title+Text pushed it to 0.931.  \n",
    "  - Similarly, MLP on **Text only** embeddings had F1 = 0.906, but adding Title raised it to ~0.926.  \n",
    "\n",
    "- **Balanced Accuracy patterns:**  \n",
    "  - BoW + Logistic Regression and BoW + MultinomialNB deliver the best balance across both classes (Balanced Accuracy ≈ 0.84).  \n",
    "  - Random Forest, while strong on F1, lags in Balanced Accuracy (0.697), indicating weaker minority-class sensitivity.  \n",
    "\n",
    "**Conclusion:**  \n",
    "Adding **Title information** improves performance across all settings, with the biggest gains seen in **BoW models** (especially MultinomialNB).  \n",
    "Among embeddings, **MLP** benefits most from Title, but still does not surpass the top BoW methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test imbalance handling in Q2, we compare **Logistic Regression (balanced class weights)** with **Logistic Regression + SMOTE oversampling**.  \n",
    "We run this comparison on both **Unweighted** and **TF-IDF Weighted embeddings** for all three input settings (Title, Text, Title+Text).  \n",
    "\n",
    "The helper `smote_compare_block` runs both pipelines, collects mean scores, and computes the **Δ (SMOTE − Balanced)** for each metric.  \n",
    "This lets us see if oversampling adds value beyond class weighting when Title information is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rep</th>\n",
       "      <th>Input</th>\n",
       "      <th>Balanced_acc</th>\n",
       "      <th>SMOTE_acc</th>\n",
       "      <th>Δ_acc</th>\n",
       "      <th>Balanced_f1</th>\n",
       "      <th>SMOTE_f1</th>\n",
       "      <th>Δ_f1</th>\n",
       "      <th>Balanced_roc_auc</th>\n",
       "      <th>SMOTE_roc_auc</th>\n",
       "      <th>Δ_roc_auc</th>\n",
       "      <th>Balanced_bacc</th>\n",
       "      <th>SMOTE_bacc</th>\n",
       "      <th>Δ_bacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title</td>\n",
       "      <td>0.8314</td>\n",
       "      <td>0.8373</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.9049</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.8359</td>\n",
       "      <td>-0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Text</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.8018</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.7884</td>\n",
       "      <td>-0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unweighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9178</td>\n",
       "      <td>-0.0015</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>-0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Title</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.8073</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>0.8072</td>\n",
       "      <td>0.8035</td>\n",
       "      <td>-0.0037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Text</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>-0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Weighted</td>\n",
       "      <td>Title+Text</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>0.8355</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.9006</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Rep       Input  Balanced_acc  SMOTE_acc   Δ_acc  Balanced_f1  \\\n",
       "0  Unweighted       Title        0.8314     0.8373  0.0060       0.8892   \n",
       "1  Unweighted        Text        0.7960     0.8018  0.0059       0.8649   \n",
       "2  Unweighted  Title+Text        0.8442     0.8522  0.0080       0.8987   \n",
       "3    Weighted       Title        0.8048     0.8073  0.0025       0.8707   \n",
       "4    Weighted        Text        0.7843     0.7941  0.0098       0.8566   \n",
       "5    Weighted  Title+Text        0.8247     0.8355  0.0108       0.8852   \n",
       "\n",
       "   SMOTE_f1    Δ_f1  Balanced_roc_auc  SMOTE_roc_auc  Δ_roc_auc  \\\n",
       "0    0.8939  0.0048            0.9078         0.9049    -0.0029   \n",
       "1    0.8698  0.0050            0.8708         0.8681    -0.0026   \n",
       "2    0.9048  0.0061            0.9193         0.9178    -0.0015   \n",
       "3    0.8730  0.0023            0.8752         0.8708    -0.0045   \n",
       "4    0.8645  0.0079            0.8601         0.8572    -0.0029   \n",
       "5    0.8935  0.0083            0.9026         0.9006    -0.0020   \n",
       "\n",
       "   Balanced_bacc  SMOTE_bacc  Δ_bacc  \n",
       "0         0.8393      0.8359 -0.0034  \n",
       "1         0.7917      0.7884 -0.0033  \n",
       "2         0.8420      0.8397 -0.0023  \n",
       "3         0.8072      0.8035 -0.0037  \n",
       "4         0.7781      0.7779 -0.0002  \n",
       "5         0.8212      0.8212 -0.0000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_bal = LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE)\n",
    "logreg_nomw = LogisticRegression(max_iter=2000, class_weight=None, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "\n",
    "def smote_compare_block(rep, input_name, X_dense):\n",
    "    pipe_bal = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", logreg_bal)])\n",
    "    pipe_smt = ImbPipeline([(\"scaler\", StandardScaler()),\n",
    "                            (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "                            (\"clf\", logreg_nomw)])\n",
    "    res_bal = cross_validate(pipe_bal, X_dense, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    res_smt = cross_validate(pipe_smt, X_dense, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    row = {\"Rep\":rep, \"Input\":input_name}\n",
    "    for m in scoring:\n",
    "        row[f\"Balanced_{m}\"] = float(np.mean(res_bal[f\"test_{m}\"]))\n",
    "        row[f\"SMOTE_{m}\"]    = float(np.mean(res_smt[f\"test_{m}\"]))\n",
    "        row[f\"Δ_{m}\"]        = row[f\"SMOTE_{m}\"] - row[f\"Balanced_{m}\"]\n",
    "    return row\n",
    "\n",
    "comp_rows = []\n",
    "# Unweighted\n",
    "comp_rows.append(smote_compare_block(\"Unweighted\", \"Title\",      X_title_unw))\n",
    "comp_rows.append(smote_compare_block(\"Unweighted\", \"Text\",       X_text_unw))\n",
    "comp_rows.append(smote_compare_block(\"Unweighted\", \"Title+Text\", X_combo_unw))\n",
    "# Weighted\n",
    "comp_rows.append(smote_compare_block(\"Weighted\", \"Title\",      X_title_w))\n",
    "comp_rows.append(smote_compare_block(\"Weighted\", \"Text\",       X_text_w))\n",
    "comp_rows.append(smote_compare_block(\"Weighted\", \"Title+Text\", X_combo_w))\n",
    "\n",
    "q2_smote_comp = pd.DataFrame(comp_rows).round(4)\n",
    "q2_smote_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison between **class weighting** and **SMOTE oversampling** shows consistent but small differences:  \n",
    "\n",
    "- **Unweighted embeddings**:  \n",
    "  - SMOTE improves **Accuracy (+0.6–0.8%)** and **F1 (+0.5–0.6%)** across all inputs (Title, Text, Title+Text).  \n",
    "  - **ROC-AUC and Balanced Accuracy** drop slightly (≈ −0.2 to −0.3%).  \n",
    "  - The best gains are seen with **Title+Text** (ΔF1 = +0.006, ΔAcc = +0.008).  \n",
    "\n",
    "- **TF-IDF Weighted embeddings**:  \n",
    "  - Similar pattern: SMOTE yields small boosts in **Accuracy and F1** (≈ +0.2 to +1.1%) but slightly reduces **ROC-AUC and Balanced Accuracy**.  \n",
    "  - The **largest relative gain** is for **Title+Text** (ΔAcc = +0.011, ΔF1 = +0.008).  \n",
    "\n",
    "**Overall:**  \n",
    "SMOTE consistently raises Accuracy and F1 but at the cost of a minor drop in ROC-AUC and Balanced Accuracy.  \n",
    "This suggests that **class weighting already handles imbalance well**, and while SMOTE provides small extra gains in F1/Accuracy, it does not improve overall robustness across all metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better summarize the SMOTE effect, we pivot the comparison table to focus on **ΔF1 (SMOTE − Balanced)**.  \n",
    "This produces a compact view showing the F1 improvement for each representation type (Unweighted, Weighted) across the three input settings (Text, Title, Title+Text).  \n",
    "\n",
    "This format makes it easier to see where SMOTE provides the most benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Input</th>\n",
       "      <th>Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>Title+Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unweighted</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted</th>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Input         Text   Title  Title+Text\n",
       "Rep                                   \n",
       "Unweighted  0.0050  0.0048      0.0061\n",
       "Weighted    0.0079  0.0023      0.0083"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_f1 = q2_smote_comp.pivot(index=[\"Rep\"], columns=[\"Input\"], values=\"Δ_f1\").fillna(0).round(4)\n",
    "delta_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ΔF1 table highlights how much SMOTE improves F1 compared to class weighting:  \n",
    "\n",
    "- **Unweighted embeddings:**  \n",
    "  - F1 increases slightly for all inputs (**+0.005 for Text, +0.005 for Title, +0.006 for Title+Text**).  \n",
    "  - The gain is most noticeable with **Title+Text**.  \n",
    "\n",
    "- **Weighted embeddings:**  \n",
    "  - Gains are small but consistent (**+0.008 for Text, +0.002 for Title, +0.008 for Title+Text**).  \n",
    "  - Again, **Title+Text** shows the strongest relative improvement.  \n",
    "\n",
    "**Takeaway:** SMOTE gives a modest F1 boost across all setups, with the largest effect when combining **Title+Text**.  \n",
    "However, the improvements remain small, confirming that class weighting already performs well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = delta_f1.plot(kind=\"bar\", figsize=(6,4), edgecolor=\"black\")\n",
    "ax.axhline(0, linewidth=1)\n",
    "ax.set_ylabel(\"Δ F1 (SMOTE - Balanced)\")\n",
    "ax.set_title(\"Q2 — SMOTE effect on embeddings\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the F1 improvement (ΔF1) when using **SMOTE vs class weighting** across embedding types and inputs:  \n",
    "\n",
    "- **Unweighted embeddings:**  \n",
    "  - SMOTE gives a small but consistent F1 boost for all inputs (~+0.005).  \n",
    "  - The best gain is for **Title+Text** (~+0.006).  \n",
    "\n",
    "- **Weighted embeddings:**  \n",
    "  - SMOTE has a stronger effect, especially for **Text (+0.008)** and **Title+Text (+0.008)**.  \n",
    "  - The gain for **Title** alone is minimal (~+0.002).  \n",
    "\n",
    "**Takeaway:** SMOTE provides modest improvements in F1, with the biggest benefits seen in **Weighted embeddings with Text or Title+Text**.  \n",
    "However, the improvements are still small overall, reinforcing that **class weighting already handles imbalance effectively**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Summary  \n",
    "\n",
    "In **Question 2**, we explored whether adding the **Title** field improves classification performance.  \n",
    "\n",
    "- **Impact of Title information:**  \n",
    "  - Adding **Title+Text** consistently improved results across all representations.  \n",
    "  - The best setup was **BoW + MultinomialNB**, reaching **F1 = 0.931, ROC-AUC = 0.931**, outperforming the Text-only baseline.  \n",
    "  - **Title alone** was weaker than Text, but still better than nothing, and combining it with Text yielded the strongest gains.  \n",
    "\n",
    "- **Model trends:**  \n",
    "  - **BoW models** remained dominant, with Naive Bayes and Random Forest leading the board.  \n",
    "  - **Embedding models** benefited most from **MLP**, which scored F1 ≈ 0.926 with Title or Title+Text, though still below BoW methods.  \n",
    "\n",
    "- **Imbalance handling (Balanced vs SMOTE):**  \n",
    "  - SMOTE gave small boosts in **Accuracy and F1** (up to +0.008) but slightly reduced **ROC-AUC and Balanced Accuracy**.  \n",
    "  - Class weighting alone remained sufficient, with SMOTE offering only marginal improvements.  \n",
    "\n",
    "**Overall:** Including Title enhances model performance, especially when combined with Text.  \n",
    "While embeddings paired with neural models (MLP) show promise, the simplest approach — **BoW + Naive Bayes with Title+Text** — remains the most effective solution for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "\n",
    "In this notebook, we built feature representations and evaluated classification models for women’s clothing reviews.  \n",
    "\n",
    "- **Task 2:** We generated three types of document representations — BoW, unweighted FastText embeddings, and TF-IDF weighted embeddings.  \n",
    "  BoW offered strong baseline features, while embeddings provided dense semantic information but required more complex models to perform well.  \n",
    "\n",
    "- **Task 3, Question 1:**  \n",
    "  - **BoW** was the most effective representation overall, with **Multinomial Naive Bayes** achieving the top F1 (≈0.923) and ROC-AUC (≈0.900).  \n",
    "  - Embeddings performed reasonably with non-linear models (MLP), but did not surpass BoW methods.  \n",
    "  - Class weighting proved sufficient for handling imbalance; SMOTE offered only minor gains.  \n",
    "\n",
    "- **Task 3, Question 2:**  \n",
    "  - Adding **Title** improved performance across all representations.  \n",
    "  - The best model was **BoW + Title+Text with Naive Bayes**, reaching **F1 ≈ 0.931**.  \n",
    "  - Title alone was weaker than Text, but in combination, it provided clear value.  \n",
    "  - Embedding models with MLP also benefited from Title, though they still trailed behind BoW approaches.  \n",
    "\n",
    "**Final takeaway:**  \n",
    "The simplest representation — **BoW combined with review Title and Text** — consistently outperformed more complex embedding-based methods.  \n",
    "This highlights how, in practice, well-preprocessed BoW features with the right model can be highly effective for text classification tasks, even compared to modern embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% [markdown]\n",
    "# # ### Export: Select best models and save reusable pipelines for the web app\n",
    "\n",
    "# # %%\n",
    "# import os, json, hashlib, datetime, joblib\n",
    "# from pathlib import Path\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# # ---------- 1) Decide which models to export (auto-detect best) ----------\n",
    "# # We prefer \"BoW + Title+Text + MultinomialNB\" based on your Q2 results.\n",
    "# # As a reliable backup, we also export \"BoW + Title+Text + LogisticRegression (balanced)\".\n",
    "\n",
    "# def _pick_best(df_q2_all_leader=None):\n",
    "#     best_primary = (\"BoW\", \"Title+Text\", \"MultinomialNB\")\n",
    "#     best_backup  = (\"BoW\", \"Title+Text\", \"LogReg (balanced)\")\n",
    "#     chosen = []\n",
    "\n",
    "#     if df_q2_all_leader is not None and {\"Rep\",\"Input\",\"Model\",\"f1_mean\"}.issubset(df_q2_all_leader.columns):\n",
    "#         # Find exact rows if they exist; otherwise fall back to top BoW + Title+Text rows.\n",
    "#         def find_row(rep, inp, model):\n",
    "#             hits = df_q2_all_leader[\n",
    "#                 (df_q2_all_leader[\"Rep\"]==rep) &\n",
    "#                 (df_q2_all_leader[\"Input\"]==inp) &\n",
    "#                 (df_q2_all_leader[\"Model\"]==model)\n",
    "#             ]\n",
    "#             return hits.iloc[0] if len(hits) else None\n",
    "\n",
    "#         r1 = find_row(*best_primary)\n",
    "#         r2 = find_row(*best_backup)\n",
    "\n",
    "#         # If not found, try the top-scoring rows constrained to BoW + Title+Text\n",
    "#         if r1 is None:\n",
    "#             cand = df_q2_all_leader[\n",
    "#                 (df_q2_all_leader[\"Rep\"]==\"BoW\") & (df_q2_all_leader[\"Input\"]==\"Title+Text\")\n",
    "#             ].sort_values([\"f1_mean\",\"roc_auc_mean\"], ascending=False)\n",
    "#             if len(cand): r1 = cand.iloc[0]\n",
    "\n",
    "#         if r2 is None:\n",
    "#             # Next best different model under same Rep/Input\n",
    "#             cand2 = df_q2_all_leader[\n",
    "#                 (df_q2_all_leader[\"Rep\"]==\"BoW\") & (df_q2_all_leader[\"Input\"]==\"Title+Text\")\n",
    "#             ].sort_values([\"f1_mean\",\"roc_auc_mean\"], ascending=False)\n",
    "#             if len(cand2) > 1:\n",
    "#                 r2 = cand2.iloc[1]\n",
    "\n",
    "#         # Build chosen list\n",
    "#         if r1 is not None:\n",
    "#             chosen.append((r1[\"Rep\"], r1[\"Input\"], r1[\"Model\"]))\n",
    "#         if r2 is not None and (r1 is None or r2[\"Model\"] != r1[\"Model\"]):\n",
    "#             chosen.append((r2[\"Rep\"], r2[\"Input\"], r2[\"Model\"]))\n",
    "\n",
    "#     # Fallback (robust defaults matching your analysis)\n",
    "#     if not chosen:\n",
    "#         chosen = [(\"BoW\",\"Title+Text\",\"MultinomialNB\"),\n",
    "#                   (\"BoW\",\"Title+Text\",\"LogReg (balanced)\")]\n",
    "#     return chosen\n",
    "\n",
    "# try:\n",
    "#     chosen_models = _pick_best(df_q2_all_leader)  # from your Q2 section\n",
    "# except NameError:\n",
    "#     # If df_q2_all_leader isn't defined, fall back gracefully\n",
    "#     chosen_models = [(\"BoW\",\"Title+Text\",\"MultinomialNB\"),\n",
    "#                      (\"BoW\",\"Title+Text\",\"LogReg (balanced)\")]\n",
    "\n",
    "# print(\"Models selected for export:\", chosen_models)\n",
    "\n",
    "# # ---------- 2) Prepare training data for the chosen setting (Title+Text with fixed vocab) ----------\n",
    "# # We reuse the same tokenization and Title/Text prep set up earlier.\n",
    "# # Inputs expected for the webapp: raw Title + processed Text tokens joined (space-separated).\n",
    "\n",
    "# # Ensure we have titles_clean, texts_clean, combo_clean, vocab, y\n",
    "# assert 'vocab' in globals(), \"Missing 'vocab' from Task 1.\"\n",
    "# assert 'y' in globals(), \"Missing target vector 'y'.\"\n",
    "# if 'titles_clean' not in globals() or 'texts_clean' not in globals() or 'combo_clean' not in globals():\n",
    "#     # Recreate if needed\n",
    "#     titles_raw = df['Title'].fillna('').astype(str) if 'Title' in df.columns else pd.Series(['']*len(df), index=df.index)\n",
    "#     texts_clean = df['processed_tokens'].fillna('').astype(str)\n",
    "#     titles_clean = titles_raw.apply(lambda s: \" \".join(tokenize(s)))\n",
    "#     combo_clean = (titles_clean.str.cat(texts_clean, sep=\" \")\n",
    "#                    .str.replace(r\"\\s+\", \" \", regex=True).str.strip())\n",
    "\n",
    "# combo_texts = combo_clean.tolist()\n",
    "\n",
    "# # Helper for vocab fingerprint (to ensure webapp matches the same vocab)\n",
    "# def _hash_vocab(vocab_dict):\n",
    "#     # Sort by token, join as \"token:index\", then md5\n",
    "#     items = [f\"{k}:{v}\" for k, v in sorted(vocab_dict.items(), key=lambda kv: kv[0])]\n",
    "#     md5 = hashlib.md5(\"\\n\".join(items).encode(\"utf-8\")).hexdigest()\n",
    "#     return md5\n",
    "\n",
    "# vocab_md5 = _hash_vocab(vocab)\n",
    "# print(\"Vocab size:\", len(vocab), \"| MD5:\", vocab_md5)\n",
    "\n",
    "# # ---------- 3) Fit pipelines and export ----------\n",
    "# EXPORT_DIR = Path(\"../export\")\n",
    "# EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# artifacts = []\n",
    "\n",
    "# def fit_and_save_bow(model_name: str):\n",
    "#     \"\"\"Build a BoW pipeline (fixed vocab) with the requested classifier name, fit, and save.\"\"\"\n",
    "#     if model_name == \"MultinomialNB\":\n",
    "#         clf = MultinomialNB()\n",
    "#         slug = \"bow_title+text_nb\"\n",
    "#     elif model_name == \"LogReg (balanced)\":\n",
    "#         clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1, random_state=42)\n",
    "#         slug = \"bow_title+text_logreg_bal\"\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unsupported model for BoW export: {model_name}\")\n",
    "\n",
    "#     pipe = Pipeline([\n",
    "#         (\"vect\", CountVectorizer(vocabulary=vocab)),\n",
    "#         (\"clf\", clf),\n",
    "#     ])\n",
    "#     pipe.fit(combo_texts, y)\n",
    "\n",
    "#     model_path = EXPORT_DIR / f\"{slug}_{timestamp}.joblib\"\n",
    "#     joblib.dump(pipe, model_path)\n",
    "\n",
    "#     meta = {\n",
    "#         \"exported_at\": timestamp,\n",
    "#         \"pipeline\": slug,\n",
    "#         \"rep\": \"BoW\",\n",
    "#         \"input\": \"Title+Text (concatenated string, space-separated tokens in Text)\",\n",
    "#         \"vectorizer\": {\n",
    "#             \"type\": \"CountVectorizer\",\n",
    "#             \"fixed_vocabulary\": True,\n",
    "#             \"vocab_size\": int(len(vocab)),\n",
    "#             \"vocab_md5\": vocab_md5\n",
    "#         },\n",
    "#         \"classifier\": model_name,\n",
    "#         \"target\": {\"name\": \"Recommended IND\", \"classes\": [0, 1]},\n",
    "#         \"expects\": {\n",
    "#             \"title\": \"raw string (may be empty)\",\n",
    "#             \"processed_text_tokens\": \"string of space-separated tokens (from Task 1 preprocessing)\",\n",
    "#             \"combined_rule\": \"combined_text = tokenize(title).join(' ') + ' ' + processed_text_tokens\"\n",
    "#         },\n",
    "#         \"files_required_in_webapp\": [\n",
    "#             \"this .joblib file only (CountVectorizer is embedded with fixed vocab)\",\n",
    "#         ],\n",
    "#         \"notes\": \"Ensure the same Task-1 preprocessing/tokenization is used to generate processed_text_tokens.\"\n",
    "#     }\n",
    "\n",
    "#     meta_path = EXPORT_DIR / f\"{slug}_{timestamp}.metadata.json\"\n",
    "#     with open(meta_path, \"w\") as f:\n",
    "#         json.dump(meta, f, indent=2)\n",
    "\n",
    "#     artifacts.append({\"model\": str(model_path), \"metadata\": str(meta_path)})\n",
    "#     print(f\"Saved: {model_path.name} and {meta_path.name}\")\n",
    "\n",
    "# # Train/export chosen models (only BoW variants are exported to keep webapp light & dependency-free)\n",
    "# for (rep, inp, model_name) in chosen_models:\n",
    "#     if rep == \"BoW\" and inp == \"Title+Text\" and model_name in {\"MultinomialNB\", \"LogReg (balanced)\"}:\n",
    "#         fit_and_save_bow(model_name)\n",
    "#     else:\n",
    "#         # Skip non-BoW exports intentionally to avoid heavy FastText dependency in the webapp bundle.\n",
    "#         print(f\"Skipping export for {rep} | {inp} | {model_name} (non-BoW models not exported).\")\n",
    "\n",
    "# # ---------- 4) Quick sanity: score the saved pipelines on all data (not CV; for validation only) ----------\n",
    "# from sklearn.metrics import f1_score, roc_auc_score, balanced_accuracy_score, accuracy_score\n",
    "\n",
    "# def quick_eval(pipe, X_text, y_true):\n",
    "#     y_pred = pipe.predict(X_text)\n",
    "#     # For AUC, need probabilities if available\n",
    "#     if hasattr(pipe[-1], \"predict_proba\"):\n",
    "#         y_proba = pipe.predict_proba(X_text)[:,1]\n",
    "#         auc = roc_auc_score(y_true, y_proba)\n",
    "#     else:\n",
    "#         # Platt scaling is not configured; fall back to decision function if available\n",
    "#         if hasattr(pipe[-1], \"decision_function\"):\n",
    "#             scores = pipe.decision_function(X_text)\n",
    "#             auc = roc_auc_score(y_true, scores)\n",
    "#         else:\n",
    "#             auc = float(\"nan\")\n",
    "#     return {\n",
    "#         \"acc\": accuracy_score(y_true, y_pred),\n",
    "#         \"f1\": f1_score(y_true, y_pred),\n",
    "#         \"bacc\": balanced_accuracy_score(y_true, y_pred),\n",
    "#         \"roc_auc\": auc,\n",
    "#     }\n",
    "\n",
    "# print(\"\\nSanity check on fitted pipelines (single full-fit evaluation):\")\n",
    "# for art in artifacts:\n",
    "#     pipe = joblib.load(art[\"model\"])\n",
    "#     scores = quick_eval(pipe, combo_texts, y)\n",
    "#     scores = {k: round(v, 4) if isinstance(v, (float,int)) else v for k,v in scores.items()}\n",
    "#     print(f\"- {Path(art['model']).name}: {scores}\")\n",
    "\n",
    "# print(\"\\nExport complete. Artifacts:\")\n",
    "# for art in artifacts:\n",
    "#     print(\"  • Model:\", art[\"model\"])\n",
    "#     print(\"    Meta :\", art[\"metadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% [markdown]\n",
    "# # ### Export: Add embedding models (Unweighted FastText + TF-IDF-Weighted FastText)\n",
    "\n",
    "# # %%\n",
    "# from pathlib import Path\n",
    "# import json, datetime\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from gensim.models import KeyedVectors\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# # ---------- 0) Reuse or (re)create inputs ----------\n",
    "# EXPORT_DIR = Path(\"../export\")\n",
    "# DATA_PATH   = \"../output/processed.csv\"\n",
    "# VOCAB_PATH  = \"../output/vocab.txt\"\n",
    "# FT_KV_PATH  = EXPORT_DIR / \"fasttext_thin.kv\"   # expect your thin KV here\n",
    "\n",
    "# # Rebuild df, vocab, y if not in globals\n",
    "# if \"df\" not in globals():\n",
    "#     df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# if \"vocab\" not in globals():\n",
    "#     vocab = {}\n",
    "#     with open(VOCAB_PATH, \"r\") as f:\n",
    "#         for ln in f:\n",
    "#             ln = ln.strip()\n",
    "#             if not ln:\n",
    "#                 continue\n",
    "#             k, v = ln.split(\":\", 1)\n",
    "#             vocab[k] = int(v.strip())\n",
    "\n",
    "# if \"y\" not in globals():\n",
    "#     y = df[\"Recommended IND\"].astype(int).to_numpy()\n",
    "\n",
    "# # Tokenizer (same as Task 1)\n",
    "# import re\n",
    "# _tokenizer = re.compile(r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\")\n",
    "# def tokenize(s: str):\n",
    "#     toks = _tokenizer.findall(str(s).lower())\n",
    "#     return [t.strip(\"-'\") for t in toks if t.strip(\"-'\")]\n",
    "\n",
    "# # Build Title/Text/Combo strings if missing\n",
    "# if \"titles_clean\" not in globals() or \"texts_clean\" not in globals() or \"combo_clean\" not in globals():\n",
    "#     titles_raw = df[\"Title\"].fillna(\"\").astype(str) if \"Title\" in df.columns else pd.Series([\"\"]*len(df), index=df.index)\n",
    "#     titles_clean = titles_raw.apply(lambda s: \" \".join(tokenize(s)))\n",
    "#     texts_clean = df[\"processed_tokens\"].fillna(\"\").astype(str)\n",
    "#     combo_clean = (titles_clean.str.cat(texts_clean, sep=\" \")\n",
    "#                    .str.replace(r\"\\s+\", \" \", regex=True).str.strip())\n",
    "\n",
    "# combo_texts = combo_clean.tolist()\n",
    "# tokenized_combo = [tokenize(t) for t in combo_texts]\n",
    "\n",
    "# # ---------- 1) Load thin FastText KeyedVectors ----------\n",
    "# if not FT_KV_PATH.exists():\n",
    "#     raise FileNotFoundError(\n",
    "#         f\"Expected KeyedVectors at {FT_KV_PATH}. \"\n",
    "#         f\"Create it first (see your 'thin FastText' export cell).\"\n",
    "#     )\n",
    "# kv = KeyedVectors.load(str(FT_KV_PATH), mmap=\"r\")\n",
    "# VECTOR_DIM = int(kv.vector_size)\n",
    "# print(f\"Loaded FastText KV: {FT_KV_PATH.name} (dim={VECTOR_DIM:,})\")\n",
    "\n",
    "# # ---------- 2) Build IDF on your Text-only corpus using fixed vocab ----------\n",
    "# # (same rule you used earlier for weighted embeddings)\n",
    "# tfidf = TfidfVectorizer(vocabulary=vocab)\n",
    "# _ = tfidf.fit_transform(df[\"processed_tokens\"].fillna(\"\").astype(str))\n",
    "# idf_weights = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))\n",
    "\n",
    "# # Save IDF for webapp reuse (so weighted embeddings match training)\n",
    "# idf_path = EXPORT_DIR / \"idf_weights.json\"\n",
    "# with open(idf_path, \"w\") as f:\n",
    "#     json.dump({k: float(v) for k, v in idf_weights.items()}, f)\n",
    "# print(f\"Saved IDF weights -> {idf_path.name} (|vocab|={len(idf_weights):,})\")\n",
    "\n",
    "# # ---------- 3) Build dense embeddings (Unweighted + Weighted) ----------\n",
    "# def avg_vec(tokens):\n",
    "#     vecs = [kv[w] for w in tokens if w in kv]\n",
    "#     if not vecs:\n",
    "#         return np.zeros(VECTOR_DIM, dtype=np.float32)\n",
    "#     return np.mean(vecs, axis=0).astype(np.float32)\n",
    "\n",
    "# def tfidf_weighted_vec(tokens):\n",
    "#     acc = None\n",
    "#     wsum = 0.0\n",
    "#     for t in tokens:\n",
    "#         if t in kv and t in idf_weights:\n",
    "#             w = float(idf_weights[t])\n",
    "#             v = kv[t] * w\n",
    "#             acc = v if acc is None else (acc + v)\n",
    "#             wsum += w\n",
    "#     if acc is None or wsum == 0.0:\n",
    "#         return np.zeros(VECTOR_DIM, dtype=np.float32)\n",
    "#     return (acc / wsum).astype(np.float32)\n",
    "\n",
    "# X_unw = np.vstack([avg_vec(toks) for toks in tokenized_combo])\n",
    "# X_w   = np.vstack([tfidf_weighted_vec(toks) for toks in tokenized_combo])\n",
    "\n",
    "# print(\"Shapes:\", \"Unweighted\", X_unw.shape, \"| Weighted\", X_w.shape)\n",
    "\n",
    "# # ---------- 4) Train lightweight embedding models (Scaler + LogReg balanced) ----------\n",
    "# RANDOM_STATE = 42\n",
    "# def make_emb_pipe():\n",
    "#     return Pipeline([\n",
    "#         (\"scaler\", StandardScaler()),\n",
    "#         (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\",\n",
    "#                                    n_jobs=-1, random_state=RANDOM_STATE))\n",
    "#     ])\n",
    "\n",
    "# pipe_unw = make_emb_pipe()\n",
    "# pipe_w   = make_emb_pipe()\n",
    "\n",
    "# pipe_unw.fit(X_unw, y)\n",
    "# pipe_w.fit(X_w, y)\n",
    "\n",
    "# # Downcast for size\n",
    "# pipe_unw[-1].coef_ = pipe_unw[-1].coef_.astype(np.float32)\n",
    "# pipe_unw[-1].intercept_ = pipe_unw[-1].intercept_.astype(np.float32)\n",
    "# pipe_w[-1].coef_ = pipe_w[-1].coef_.astype(np.float32)\n",
    "# pipe_w[-1].intercept_ = pipe_w[-1].intercept_.astype(np.float32)\n",
    "\n",
    "# # ---------- 5) Save models + metadata ----------\n",
    "# timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# def save_model(pipe, slug, extra_meta=None):\n",
    "#     p = EXPORT_DIR / f\"{slug}_{timestamp}.joblib\"\n",
    "#     joblib.dump(pipe, p, compress=(\"xz\", 3), protocol=5)\n",
    "#     meta = {\n",
    "#         \"exported_at\": timestamp,\n",
    "#         \"pipeline\": slug,\n",
    "#         \"rep\": \"Embeddings\",\n",
    "#         \"input\": \"Title+Text (Title tokenized; Text = space-joined tokens)\",\n",
    "#         \"embedding\": {\n",
    "#             \"type\": \"FastText KeyedVectors\",\n",
    "#             \"file\": str(FT_KV_PATH.name),\n",
    "#             \"vector_dim\": VECTOR_DIM,\n",
    "#             \"unweighted\": slug.endswith(\"_unweighted\"),\n",
    "#             \"weighted_tfidf\": slug.endswith(\"_weighted\"),\n",
    "#         },\n",
    "#         \"preprocessing_notes\": [\n",
    "#             \"Title is tokenized with the assignment regex.\",\n",
    "#             \"Text comes from Task-1 preprocessing (space-joined tokens).\",\n",
    "#             \"For weighted model, use idf_weights.json with same vocab.\"\n",
    "#         ],\n",
    "#         \"target\": {\"name\": \"Recommended IND\", \"classes\": [0, 1]},\n",
    "#     }\n",
    "#     if extra_meta: meta.update(extra_meta)\n",
    "#     with open(EXPORT_DIR / f\"{slug}_{timestamp}.metadata.json\", \"w\") as f:\n",
    "#         json.dump(meta, f, indent=2)\n",
    "#     return p\n",
    "\n",
    "# m_unw = save_model(pipe_unw, \"emb_logreg_bal_unweighted\")\n",
    "# m_w   = save_model(pipe_w,   \"emb_logreg_bal_weighted\", extra_meta={\"idf_file\": idf_path.name})\n",
    "\n",
    "# print(\"Saved:\")\n",
    "# print(\" -\", m_unw.name)\n",
    "# print(\" -\", m_w.name)\n",
    "\n",
    "# # ---------- 6) Quick sanity (single full-fit eval) ----------\n",
    "# from sklearn.metrics import f1_score, roc_auc_score, balanced_accuracy_score, accuracy_score\n",
    "\n",
    "# def quick_eval_dense(pipe, X, y_true):\n",
    "#     y_pred = pipe.predict(X)\n",
    "#     if hasattr(pipe[-1], \"predict_proba\"):\n",
    "#         y_proba = pipe[-1].predict_proba(pipe[0].transform(X))[:, 1] if isinstance(pipe[0], StandardScaler) else pipe.predict_proba(X)[:, 1]\n",
    "#     else:\n",
    "#         # LR has predict_proba; keeping fallback for safety\n",
    "#         y_proba = None\n",
    "#     scores = {\n",
    "#         \"acc\": accuracy_score(y_true, y_pred),\n",
    "#         \"f1\": f1_score(y_true, y_pred),\n",
    "#         \"bacc\": balanced_accuracy_score(y_true, y_pred),\n",
    "#         \"roc_auc\": roc_auc_score(y_true, y_proba) if y_proba is not None else float(\"nan\")\n",
    "#     }\n",
    "#     return {k: (round(v, 4) if isinstance(v, (float, int)) else v) for k, v in scores.items()}\n",
    "\n",
    "# print(\"\\nSanity check (dense models):\")\n",
    "# print(\" Unweighted:\", quick_eval_dense(pipe_unw, X_unw, y))\n",
    "# print(\" Weighted  :\", quick_eval_dense(pipe_w,   X_w,   y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% [markdown]\n",
    "# # ### Export a \"thin\" FastText (KeyedVectors only)\n",
    "\n",
    "# # %%\n",
    "# from gensim.models import FastText, KeyedVectors\n",
    "\n",
    "# # Tokenized reviews (already created earlier as `tokenized_reviews`)\n",
    "# # Each element: list of tokens for one review\n",
    "# assert 'tokenized_reviews' in globals(), \"tokenized_reviews not found — make sure Task 2 has run.\"\n",
    "\n",
    "# # 1) Train a small FastText on our 19k reviews\n",
    "# ft_thin = FastText(\n",
    "#     sentences=tokenized_reviews,\n",
    "#     vector_size=50,    # smaller dimension (vs 300)\n",
    "#     window=5,\n",
    "#     min_count=2,        # ignore rare words (appearing <2 times)\n",
    "#     sg=1,               # skip-gram for better quality\n",
    "#     epochs=10,\n",
    "#     workers=4,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# # 2) Extract only KeyedVectors (drop training weights)\n",
    "# kv = ft_thin.wv\n",
    "\n",
    "# # 3) Optionally trim to our vocab (already limited by min_count)\n",
    "# # kv = kv  # already aligned with corpus\n",
    "\n",
    "# # 4) Save KeyedVectors (≈ much smaller than full model)\n",
    "# ARTIFACT_DIR = Path(\"../export\")\n",
    "# ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# kv_path = ARTIFACT_DIR / \"fasttext_thin.kv\"\n",
    "# kv.save(str(kv_path))\n",
    "\n",
    "# print(f\"Saved thin FastText KeyedVectors -> {kv_path}\")\n",
    "# print(\"Reload later with:\")\n",
    "# print(\"  from gensim.models import KeyedVectors\")\n",
    "# print(f\"  kv = KeyedVectors.load('{kv_path}', mmap='r')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% [markdown]\n",
    "# # ### Sanity tests: Joblib models + Thin FastText\n",
    "\n",
    "# # %%\n",
    "# import joblib\n",
    "# from gensim.models import KeyedVectors\n",
    "# import numpy as np\n",
    "\n",
    "# # --- Paths ---\n",
    "# EXPORT_DIR = Path(\"../export\")\n",
    "\n",
    "# # Update filenames if you saved different timestamps\n",
    "# model_nb_path   = sorted(EXPORT_DIR.glob(\"bow_title+text_nb_*.joblib\"))[-1]\n",
    "# model_lr_path   = sorted(EXPORT_DIR.glob(\"bow_title+text_logreg_bal_*.joblib\"))[-1]\n",
    "# ft_kv_path      = EXPORT_DIR / \"fasttext_thin.kv\"\n",
    "\n",
    "# print(\"Using models:\")\n",
    "# print(\" Naive Bayes :\", model_nb_path.name)\n",
    "# print(\" LogisticReg :\", model_lr_path.name)\n",
    "# print(\" FastText KV :\", ft_kv_path.name)\n",
    "\n",
    "# # --- Load models ---\n",
    "# pipe_nb = joblib.load(model_nb_path)\n",
    "# pipe_lr = joblib.load(model_lr_path)\n",
    "# kv      = KeyedVectors.load(str(ft_kv_path), mmap=\"r\")\n",
    "\n",
    "# # --- Sample processed tokens (mimic Task 1 output) ---\n",
    "# samples = [\n",
    "#     \"love soft fabric fit perfectly\",       # strongly positive\n",
    "#     \"material poor quality tore after wash\",# negative\n",
    "#     \"dress nice but size runs small\",       # mixed\n",
    "# ]\n",
    "\n",
    "# print(\"\\n=== BoW Classifier Predictions ===\")\n",
    "# for s in samples:\n",
    "#     pred_nb = pipe_nb.predict([s])[0]\n",
    "#     prob_nb = (pipe_nb.predict_proba([s])[0][1]\n",
    "#                if hasattr(pipe_nb[-1], \"predict_proba\") else None)\n",
    "\n",
    "#     pred_lr = pipe_lr.predict([s])[0]\n",
    "#     prob_lr = (pipe_lr.predict_proba([s])[0][1]\n",
    "#                if hasattr(pipe_lr[-1], \"predict_proba\") else None)\n",
    "\n",
    "#     print(f\"\\nReview: {s!r}\")\n",
    "#     print(f\" NB → label={pred_nb} prob={prob_nb:.3f}\" if prob_nb is not None else f\" NB → label={pred_nb}\")\n",
    "#     print(f\" LR → label={pred_lr} prob={prob_lr:.3f}\" if prob_lr is not None else f\" LR → label={pred_lr}\")\n",
    "\n",
    "# print(\"\\n=== FastText Embedding Check ===\")\n",
    "# tokens = [\"dress\", \"fabric\", \"quality\", \"unknownword\"]\n",
    "# for t in tokens:\n",
    "#     if t in kv:\n",
    "#         vec = kv[t][:5]  # show first 5 dims\n",
    "#         print(f\"{t:12s} → [{', '.join(f'{v:.3f}' for v in vec)} ...]\")\n",
    "#     else:\n",
    "#         print(f\"{t:12s} → [OOV]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================\n",
      "Training thin FastText (KeyedVectors only)\n",
      "==========================================\n",
      "Saved                     : fasttext_thin.kv\n",
      "\n",
      "======================================\n",
      "Model Inputs (What to feed each model)\n",
      "======================================\n",
      "• BoW models (NB, LogReg):\n",
      "  - INPUT TYPE: Text string\n",
      "  - FORMAT    : \"<title_as_tokens> <processed_text_tokens>\" (space-joined)\n",
      "  - VECTORIZE : CountVectorizer with fixed Task-1 vocabulary (embedded inside pipeline)\n",
      "• Embedding models (Unweighted, Weighted):\n",
      "  - INPUT TYPE: NumPy vector (shape = (VECTOR_DIM,))\n",
      "  - HOW TO GET:\n",
      "      Unweighted → mean( kv[w] for w in tokens if w in kv )\n",
      "      Weighted   → mean( kv[w] * idf[w] ), using idf_weights.json\n",
      "VECTOR_DIM                : 50\n",
      "KV file                   : fasttext_thin.kv\n",
      "IDF file (weighted only)  : idf_weights.json\n",
      "\n",
      "============================================================\n",
      "Sanity metrics on training data (single full-fit evaluation)\n",
      "============================================================\n",
      "- BoW  + NB          | Accuracy: 0.91 | F1-score: 0.944 | Balanced Acc: 0.8806 | ROC AUC: 0.9551\n",
      "- BoW  + LogReg(b)   | Accuracy: 0.9388 | F1-score: 0.9614 | Balanced Acc: 0.9511 | ROC AUC: 0.9843\n",
      "- Emb  + Unweighted  | Accuracy: 0.8632 | F1-score: 0.9113 | Balanced Acc: 0.8706 | ROC AUC: 0.9373\n",
      "- Emb  + Weighted    | Accuracy: 0.8541 | F1-score: 0.9052 | Balanced Acc: 0.8593 | ROC AUC: 0.9304\n",
      "\n",
      "===================================\n",
      "Sample predictions (human-readable)\n",
      "===================================\n",
      "\n",
      "Input (processed): 'love soft fabric fit perfectly'\n",
      "  BoW  → NB            | label = 1  | prob = 0.955\n",
      "  BoW  → LogReg(bal)   | label = 1  | prob = 0.86\n",
      "  Emb  → Unweighted    | label = 1 | prob = 0.952\n",
      "  Emb  → TFIDF-Weighted| label = 1  | prob = 0.928\n",
      "\n",
      "Input (processed): 'material poor quality tore after wash'\n",
      "  BoW  → NB            | label = 0  | prob = 0.012\n",
      "  BoW  → LogReg(bal)   | label = 0  | prob = 0.088\n",
      "  Emb  → Unweighted    | label = 0 | prob = 0.003\n",
      "  Emb  → TFIDF-Weighted| label = 0  | prob = 0.01\n",
      "\n",
      "Input (processed): 'dress nice but size runs small'\n",
      "  BoW  → NB            | label = 1  | prob = 0.933\n",
      "  BoW  → LogReg(bal)   | label = 1  | prob = 0.861\n",
      "  Emb  → Unweighted    | label = 0 | prob = 0.307\n",
      "  Emb  → TFIDF-Weighted| label = 1  | prob = 0.896\n",
      "\n",
      "==================\n",
      "Exported artifacts\n",
      "==================\n",
      "bow_title+text_nb.joblib  : 68.0 KB\n",
      "bow_title+text_nb.metadata.json: 484.0 B\n",
      "bow_title+text_logreg_bal.joblib: 64.0 KB\n",
      "bow_title+text_logreg_bal.metadata.json: 508.0 B\n",
      "emb_logreg_bal_unweighted.joblib: 2.2 KB\n",
      "emb_logreg_bal_unweighted.metadata.json: 661.0 B\n",
      "emb_logreg_bal_weighted.joblib: 2.2 KB\n",
      "emb_logreg_bal_weighted.metadata.json: 672.0 B\n",
      "fasttext_thin.kv          : 1.5 MB\n",
      "idf_weights.json          : 190.4 KB\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Unified export + test: BoW & Embedding models (stable filenames, pro report)\n",
    "\n",
    "# %%\n",
    "import os, json, hashlib, datetime, math, re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from gensim.models import FastText, KeyedVectors\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    ")\n",
    "\n",
    "# ---------------------------- Config & Paths ----------------------------\n",
    "DATA_PATH   = \"../output/processed.csv\"\n",
    "VOCAB_PATH  = \"../output/vocab.txt\"\n",
    "EXPORT_DIR  = Path(\"../export\"); EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Stable filenames (no timestamps)\n",
    "FN_BOW_NB        = EXPORT_DIR / \"bow_title+text_nb.joblib\"\n",
    "FN_BOW_LR        = EXPORT_DIR / \"bow_title+text_logreg_bal.joblib\"\n",
    "FN_EMB_UNW_LR    = EXPORT_DIR / \"emb_logreg_bal_unweighted.joblib\"\n",
    "FN_EMB_W_LR      = EXPORT_DIR / \"emb_logreg_bal_weighted.joblib\"\n",
    "FN_IDF_JSON      = EXPORT_DIR / \"idf_weights.json\"\n",
    "FN_FT_KV         = EXPORT_DIR / \"fasttext_thin.kv\"\n",
    "\n",
    "FN_BOW_NB_META   = EXPORT_DIR / \"bow_title+text_nb.metadata.json\"\n",
    "FN_BOW_LR_META   = EXPORT_DIR / \"bow_title+text_logreg_bal.metadata.json\"\n",
    "FN_EMB_UNW_META  = EXPORT_DIR / \"emb_logreg_bal_unweighted.metadata.json\"\n",
    "FN_EMB_W_META    = EXPORT_DIR / \"emb_logreg_bal_weighted.metadata.json\"\n",
    "\n",
    "# Thin FastText training params (used only if KV missing)\n",
    "FT_VECTOR_SIZE   = 50\n",
    "FT_MIN_COUNT     = 2\n",
    "FT_EPOCHS        = 10\n",
    "RANDOM_STATE     = 42\n",
    "\n",
    "# ---------------------------- Helpers ----------------------------\n",
    "_tokenizer = re.compile(r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\")\n",
    "\n",
    "def tokenize(s: str):\n",
    "    toks = _tokenizer.findall(str(s).lower())\n",
    "    return [t.strip(\"-'\") for t in toks if t.strip(\"-'\")]\n",
    "\n",
    "def md5_vocab(vocab_dict):\n",
    "    items = [f\"{k}:{v}\" for k, v in sorted(vocab_dict.items(), key=lambda kv: kv[0])]\n",
    "    return hashlib.md5(\"\\n\".join(items).encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def human_size(n):\n",
    "    for u in [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]:\n",
    "        if n < 1024: return f\"{n:.1f} {u}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.1f} PB\"\n",
    "\n",
    "def print_section(title):\n",
    "    print(\"\\n\" + \"=\"*len(title))\n",
    "    print(title)\n",
    "    print(\"=\"*len(title))\n",
    "\n",
    "def print_kv(k, v, pad=26):\n",
    "    print(f\"{k:<{pad}}: {v}\")\n",
    "\n",
    "def metric_dict(y_true, y_pred, y_score=None):\n",
    "    out = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"F1-score\": f1_score(y_true, y_pred),\n",
    "        \"Balanced Acc\": balanced_accuracy_score(y_true, y_pred),\n",
    "    }\n",
    "    if y_score is not None and np.isfinite(y_score).all():\n",
    "        try:\n",
    "            out[\"ROC AUC\"] = roc_auc_score(y_true, y_score)\n",
    "        except Exception:\n",
    "            out[\"ROC AUC\"] = float(\"nan\")\n",
    "    else:\n",
    "        out[\"ROC AUC\"] = float(\"nan\")\n",
    "    return {k: round(float(v), 4) if isinstance(v, (int,float)) and math.isfinite(v) else v for k,v in out.items()}\n",
    "\n",
    "# ---------------------------- Load core data ----------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "assert {'processed_tokens','Recommended IND'}.issubset(df.columns), \\\n",
    "    \"processed.csv must contain 'processed_tokens' and 'Recommended IND'.\"\n",
    "\n",
    "# Target\n",
    "y = df[\"Recommended IND\"].astype(int).to_numpy()\n",
    "\n",
    "# Load fixed Task-1 vocab\n",
    "vocab = {}\n",
    "with open(VOCAB_PATH, \"r\") as f:\n",
    "    for ln in f:\n",
    "        ln = ln.strip()\n",
    "        if not ln: continue\n",
    "        k, v = ln.split(\":\", 1)\n",
    "        vocab[k] = int(v.strip())\n",
    "vocab_md5 = md5_vocab(vocab)\n",
    "\n",
    "# Build Title/Text/Combo\n",
    "titles_clean = (df[\"Title\"].fillna(\"\").astype(str).apply(lambda s: \" \".join(tokenize(s)))\n",
    "                if \"Title\" in df.columns else pd.Series([\"\"]*len(df), index=df.index))\n",
    "texts_clean  = df[\"processed_tokens\"].fillna(\"\").astype(str)\n",
    "combo_clean  = (titles_clean.str.cat(texts_clean, sep=\" \").str.replace(r\"\\s+\",\" \",regex=True).str.strip())\n",
    "combo_texts  = combo_clean.tolist()\n",
    "tokenized_combo = [tokenize(s) for s in combo_texts]\n",
    "\n",
    "# ---------------------------- Ensure FastText KV ----------------------------\n",
    "if FN_FT_KV.exists():\n",
    "    kv = KeyedVectors.load(str(FN_FT_KV), mmap=\"r\")\n",
    "else:\n",
    "    print_section(\"Training thin FastText (KeyedVectors only)\")\n",
    "    ft = FastText(\n",
    "        sentences=tokenized_combo, vector_size=FT_VECTOR_SIZE, min_count=FT_MIN_COUNT,\n",
    "        window=5, sg=1, epochs=FT_EPOCHS, workers=4, seed=RANDOM_STATE\n",
    "    )\n",
    "    kv = ft.wv\n",
    "    kv.save(str(FN_FT_KV))\n",
    "    print_kv(\"Saved\", FN_FT_KV.name)\n",
    "VECTOR_DIM = int(kv.vector_size)\n",
    "\n",
    "# ---------------------------- Build IDF (Text-only) & Save ----------------------------\n",
    "tfidf = TfidfVectorizer(vocabulary=vocab)\n",
    "_ = tfidf.fit_transform(texts_clean)\n",
    "idf_weights = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))\n",
    "with open(FN_IDF_JSON, \"w\") as f:\n",
    "    json.dump({k: float(v) for k,v in idf_weights.items()}, f)\n",
    "\n",
    "# ---------------------------- Train & Export: BoW models ----------------------------\n",
    "def build_bow_pipeline(clf):\n",
    "    return Pipeline([(\"vect\", CountVectorizer(vocabulary=vocab)),\n",
    "                     (\"clf\", clf)])\n",
    "\n",
    "# Multinomial NB\n",
    "pipe_bow_nb = build_bow_pipeline(MultinomialNB())\n",
    "pipe_bow_nb.fit(combo_texts, y)\n",
    "joblib.dump(pipe_bow_nb, FN_BOW_NB, compress=(\"xz\", 3), protocol=5)\n",
    "\n",
    "# Logistic Regression (balanced)\n",
    "pipe_bow_lr = build_bow_pipeline(LogisticRegression(\n",
    "    max_iter=2000, class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE))\n",
    "pipe_bow_lr.fit(combo_texts, y)\n",
    "# Downcast for size\n",
    "pipe_bow_lr[-1].coef_      = pipe_bow_lr[-1].coef_.astype(np.float32)\n",
    "pipe_bow_lr[-1].intercept_ = pipe_bow_lr[-1].intercept_.astype(np.float32)\n",
    "joblib.dump(pipe_bow_lr, FN_BOW_LR, compress=(\"xz\", 3), protocol=5)\n",
    "\n",
    "# Metadata for BoW models\n",
    "def save_meta(path, classifier_name):\n",
    "    meta = {\n",
    "        \"pipeline\": Path(path).name,\n",
    "        \"type\": \"BoW\",\n",
    "        \"input_expected\": \"Single string: Title tokens + space + processed_text_tokens\",\n",
    "        \"vectorizer\": {\n",
    "            \"CountVectorizer_fixed_vocab\": True,\n",
    "            \"vocab_size\": len(vocab),\n",
    "            \"vocab_md5\": vocab_md5\n",
    "        },\n",
    "        \"classifier\": classifier_name,\n",
    "        \"target\": {\"name\":\"Recommended IND\",\"classes\":[0,1]},\n",
    "        \"notes\": \"Preprocess the same as Task-1 to create processed_text_tokens.\"\n",
    "    }\n",
    "    with open(Path(str(path).replace(\".joblib\",\".metadata.json\")), \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "save_meta(FN_BOW_NB, \"MultinomialNB\")\n",
    "save_meta(FN_BOW_LR, \"LogisticRegression (balanced)\")\n",
    "\n",
    "# ---------------------------- Train & Export: Embedding models ----------------------------\n",
    "def avg_vec(tokens):\n",
    "    vecs = [kv[w] for w in tokens if w in kv]\n",
    "    return (np.mean(vecs, axis=0).astype(np.float32) if vecs\n",
    "            else np.zeros(VECTOR_DIM, dtype=np.float32))\n",
    "\n",
    "def tfidf_weighted_vec(tokens):\n",
    "    acc = None; wsum = 0.0\n",
    "    for t in tokens:\n",
    "        if t in kv and t in idf_weights:\n",
    "            w = float(idf_weights[t]); v = kv[t] * w\n",
    "            acc = v if acc is None else (acc + v); wsum += w\n",
    "    return (acc / wsum).astype(np.float32) if (acc is not None and wsum>0) \\\n",
    "           else np.zeros(VECTOR_DIM, dtype=np.float32)\n",
    "\n",
    "# Dense matrices\n",
    "X_unw = np.vstack([avg_vec(toks) for toks in tokenized_combo])\n",
    "X_w   = np.vstack([tfidf_weighted_vec(toks) for toks in tokenized_combo])\n",
    "\n",
    "def make_emb_pipe():\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\",\n",
    "                                   n_jobs=-1, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "pipe_emb_unw = make_emb_pipe(); pipe_emb_unw.fit(X_unw, y)\n",
    "pipe_emb_unw[-1].coef_ = pipe_emb_unw[-1].coef_.astype(np.float32)\n",
    "pipe_emb_unw[-1].intercept_ = pipe_emb_unw[-1].intercept_.astype(np.float32)\n",
    "joblib.dump(pipe_emb_unw, FN_EMB_UNW_LR, compress=(\"xz\", 3), protocol=5)\n",
    "\n",
    "pipe_emb_w = make_emb_pipe(); pipe_emb_w.fit(X_w, y)\n",
    "pipe_emb_w[-1].coef_ = pipe_emb_w[-1].coef_.astype(np.float32)\n",
    "pipe_emb_w[-1].intercept_ = pipe_emb_w[-1].intercept_.astype(np.float32)\n",
    "joblib.dump(pipe_emb_w, FN_EMB_W_LR, compress=(\"xz\", 3), protocol=5)\n",
    "\n",
    "# Metadata for Embedding models\n",
    "def save_emb_meta(path, weighted: bool):\n",
    "    meta = {\n",
    "        \"pipeline\": Path(path).name,\n",
    "        \"type\": \"Embeddings\",\n",
    "        \"input_expected\": \"NumPy vector of shape (VECTOR_DIM,) computed from Title+Text tokens\",\n",
    "        \"embedding\": {\n",
    "            \"kv_file\": FN_FT_KV.name,\n",
    "            \"vector_dim\": VECTOR_DIM,\n",
    "            \"weighted_tfidf\": bool(weighted),\n",
    "            \"idf_file\": FN_IDF_JSON.name if weighted else None\n",
    "        },\n",
    "        \"classifier\": \"LogisticRegression (balanced)\",\n",
    "        \"target\": {\"name\":\"Recommended IND\",\"classes\":[0,1]},\n",
    "        \"notes\": [\n",
    "            \"Tokenize title with assignment regex; text is Task-1 space-joined tokens.\",\n",
    "            \"Unweighted: average kv[w] for in-vocab tokens.\",\n",
    "            \"Weighted: average kv[w]*idf[w] with weights from idf_weights.json.\"\n",
    "        ]\n",
    "    }\n",
    "    with open(Path(str(path).replace(\".joblib\",\".metadata.json\")), \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "save_emb_meta(FN_EMB_UNW_LR, weighted=False)\n",
    "save_emb_meta(FN_EMB_W_LR,   weighted=True)\n",
    "\n",
    "# ---------------------------- REPORT: What each model expects ----------------------------\n",
    "print_section(\"Model Inputs (What to feed each model)\")\n",
    "print(\"• BoW models (NB, LogReg):\")\n",
    "print(\"  - INPUT TYPE: Text string\")\n",
    "print(\"  - FORMAT    : \\\"<title_as_tokens> <processed_text_tokens>\\\" (space-joined)\")\n",
    "print(\"  - VECTORIZE : CountVectorizer with fixed Task-1 vocabulary (embedded inside pipeline)\")\n",
    "print(\"• Embedding models (Unweighted, Weighted):\")\n",
    "print(\"  - INPUT TYPE: NumPy vector (shape = (VECTOR_DIM,))\")\n",
    "print(\"  - HOW TO GET:\")\n",
    "print(\"      Unweighted → mean( kv[w] for w in tokens if w in kv )\")\n",
    "print(\"      Weighted   → mean( kv[w] * idf[w] ), using idf_weights.json\")\n",
    "print_kv(\"VECTOR_DIM\", VECTOR_DIM)\n",
    "print_kv(\"KV file\", FN_FT_KV.name)\n",
    "print_kv(\"IDF file (weighted only)\", FN_IDF_JSON.name)\n",
    "\n",
    "# ---------------------------- TESTS: Full-fit sanity metrics ----------------------------\n",
    "print_section(\"Sanity metrics on training data (single full-fit evaluation)\")\n",
    "def eval_bow(pipe):\n",
    "    y_pred = pipe.predict(combo_texts)\n",
    "    y_score = None\n",
    "    if hasattr(pipe[-1], \"predict_proba\"):\n",
    "        y_score = pipe.predict_proba(combo_texts)[:,1]\n",
    "    elif hasattr(pipe[-1], \"decision_function\"):\n",
    "        y_score = pipe.decision_function(combo_texts)\n",
    "    return metric_dict(y, y_pred, y_score)\n",
    "\n",
    "def eval_emb(pipe, X):\n",
    "    y_pred  = pipe.predict(X)\n",
    "    y_score = pipe[-1].predict_proba(pipe[0].transform(X))[:,1] if hasattr(pipe[-1], \"predict_proba\") else None\n",
    "    return metric_dict(y, y_pred, y_score)\n",
    "\n",
    "results = [\n",
    "    (\"BoW  + NB\",        eval_bow(pipe_bow_nb)),\n",
    "    (\"BoW  + LogReg(b)\", eval_bow(pipe_bow_lr)),\n",
    "    (\"Emb  + Unweighted\",eval_emb(pipe_emb_unw, X_unw)),\n",
    "    (\"Emb  + Weighted\",  eval_emb(pipe_emb_w,   X_w)),\n",
    "]\n",
    "for name, scores in results:\n",
    "    print(f\"- {name:<18} | \" + \" | \".join(f\"{k}: {v}\" for k,v in scores.items()))\n",
    "\n",
    "# ---------------------------- TESTS: Readable sample predictions ----------------------------\n",
    "print_section(\"Sample predictions (human-readable)\")\n",
    "samples = [\n",
    "    # These strings should mimic your deployment input (already tokenized text)\n",
    "    (\"\", \"love soft fabric fit perfectly\"),          # positive\n",
    "    (\"\", \"material poor quality tore after wash\"),   # negative\n",
    "    (\"\", \"dress nice but size runs small\")           # mixed\n",
    "]\n",
    "\n",
    "def assemble(title_str, tokens_str):\n",
    "    title_tok = \" \".join(tokenize(title_str)) if title_str else \"\"\n",
    "    join = (title_tok + \" \" + tokens_str).strip()\n",
    "    return re.sub(r\"\\s+\", \" \", join)\n",
    "\n",
    "def emb_vec_from_text(title_str, tokens_str, weighted=False):\n",
    "    toks = tokenize(title_str) + tokens_str.split()\n",
    "    if weighted:\n",
    "        return tfidf_weighted_vec(toks)\n",
    "    return avg_vec(toks)\n",
    "\n",
    "for title, proc_tokens in samples:\n",
    "    combined = assemble(title, proc_tokens)\n",
    "    # BoW predictions\n",
    "    pred_nb = pipe_bow_nb.predict([combined])[0]\n",
    "    proba_nb = pipe_bow_nb.predict_proba([combined])[0][1] if hasattr(pipe_bow_nb[-1],\"predict_proba\") else None\n",
    "    pred_lr = pipe_bow_lr.predict([combined])[0]\n",
    "    proba_lr = pipe_bow_lr.predict_proba([combined])[0][1] if hasattr(pipe_bow_lr[-1],\"predict_proba\") else None\n",
    "\n",
    "    # Embeddings predictions\n",
    "    x_unw = emb_vec_from_text(title, proc_tokens, weighted=False).reshape(1, -1)\n",
    "    x_w   = emb_vec_from_text(title, proc_tokens, weighted=True ).reshape(1, -1)\n",
    "    pred_unw = pipe_emb_unw.predict(x_unw)[0]\n",
    "    proba_unw = pipe_emb_unw[-1].predict_proba(pipe_emb_unw[0].transform(x_unw))[0][1]\n",
    "    pred_w   = pipe_emb_w.predict(x_w)[0]\n",
    "    proba_w  = pipe_emb_w[-1].predict_proba(pipe_emb_w[0].transform(x_w))[0][1]\n",
    "\n",
    "    print(f\"\\nInput (processed): {combined!r}\")\n",
    "    print(\"  BoW  → NB            | label =\", int(pred_nb), \" | prob =\", None if proba_nb is None else round(float(proba_nb),3))\n",
    "    print(\"  BoW  → LogReg(bal)   | label =\", int(pred_lr), \" | prob =\", None if proba_lr is None else round(float(proba_lr),3))\n",
    "    print(\"  Emb  → Unweighted    | label =\", int(pred_unw), \"| prob =\", round(float(proba_unw),3))\n",
    "    print(\"  Emb  → TFIDF-Weighted| label =\", int(pred_w),  \" | prob =\", round(float(proba_w),3))\n",
    "\n",
    "# ---------------------------- Artifact sizes ----------------------------\n",
    "print_section(\"Exported artifacts\")\n",
    "for p in [FN_BOW_NB, FN_BOW_NB_META, FN_BOW_LR, FN_BOW_LR_META,\n",
    "          FN_EMB_UNW_LR, FN_EMB_UNW_META, FN_EMB_W_LR, FN_EMB_W_META,\n",
    "          FN_FT_KV, FN_IDF_JSON]:\n",
    "    if Path(p).exists():\n",
    "        print_kv(Path(p).name, human_size(os.path.getsize(p)))\n",
    "    else:\n",
    "        print_kv(Path(p).name, \"MISSING\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap4ds-a3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
